{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RotinasDeLimpezaDaBaseDeDados.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LuanPCunha/TCC/blob/main/RotinasDeLimpezaDaBaseDeDados.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U8-4D6gHR9cH",
        "outputId": "052ef137-3468-4b31-fbb1-a029b743ff1e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "85MWVC-MRkEq"
      },
      "source": [
        "Base de Dados Twitter\n",
        "\n",
        "Análise da base de dados do Twitter com linguagem ofensiva\n",
        "\n",
        "Pré - Processamento do texto\n",
        "\n",
        "Classificação"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QhJufh39Rono"
      },
      "source": [
        "Import e instalação das bibliotecas necessárias"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lhGx5h16Rj0l",
        "outputId": "ccf41b0a-3362-4ba6-fedd-ef6cf7c98f8b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#Install e downloads\n",
        "!pip install emoji\n",
        "!pip install pandas\n",
        "!pip install nltk\n",
        "#nltk.download('all-nltk') #Demora um pouco"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting emoji\n",
            "  Downloading emoji-1.7.0.tar.gz (175 kB)\n",
            "\u001b[?25l\r\u001b[K     |█▉                              | 10 kB 16.2 MB/s eta 0:00:01\r\u001b[K     |███▊                            | 20 kB 20.2 MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 30 kB 17.5 MB/s eta 0:00:01\r\u001b[K     |███████▌                        | 40 kB 11.5 MB/s eta 0:00:01\r\u001b[K     |█████████▍                      | 51 kB 5.5 MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 61 kB 6.3 MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 71 kB 7.0 MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 81 kB 6.7 MB/s eta 0:00:01\r\u001b[K     |████████████████▉               | 92 kB 7.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████▊             | 102 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████▌           | 112 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▍         | 122 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 133 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 143 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 153 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▉  | 163 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▊| 174 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 175 kB 8.0 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: emoji\n",
            "  Building wheel for emoji (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for emoji: filename=emoji-1.7.0-py3-none-any.whl size=171046 sha256=b7776c99a2769d69f84f6da9f18d3a701e02d856573091515f11ecf3b857c331\n",
            "  Stored in directory: /root/.cache/pip/wheels/8a/4e/b6/57b01db010d17ef6ea9b40300af725ef3e210cb1acfb7ac8b6\n",
            "Successfully built emoji\n",
            "Installing collected packages: emoji\n",
            "Successfully installed emoji-1.7.0\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (1.3.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.7/dist-packages (from pandas) (1.21.5)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas) (2018.9)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas) (1.15.0)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (3.2.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from nltk) (1.15.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CVE3AI4FRwiJ"
      },
      "source": [
        "#Imports\n",
        "import pandas as pd\n",
        "from nltk.tokenize import RegexpTokenizer\n",
        "import re\n",
        "import itertools"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4gx9VCYwRzhC"
      },
      "source": [
        "# Definição de constantes\n",
        "\n",
        "# Padrão RegEx\n",
        "PADRAO_PALAVRAS_PT = r'[a-zA-Zà-úÀ-Ú0-9]+'\n",
        "\n",
        "# Quantidade tokens tweets pequeno\n",
        "QUANT_TOKENS_MIN = 3\n",
        "\n",
        "########## PATHS DE ARQUIVOS ##########\n",
        "# Base completa bruta\n",
        "PATH_BASE_COMPLETA_BRUTA = r\"/content/drive/MyDrive/TCC/dados/tweets_coletados/base80k.csv\"\n",
        "\n",
        "# Base teste bruta\n",
        "PATH_BASE_TESTE_BRUTA = r\"/content/drive/MyDrive/TCC/dados/tweets_coletados/base_teste.csv\"\n",
        "\n",
        "# Dicionário de palavrões\n",
        "PATH_DICT_PALAVROES = r\"/content/drive/MyDrive/TCC/dados/dicionarios/badword_list.csv\"\n",
        "\n",
        "# Dicionário de internetes\n",
        "PATH_DICT_INTERNETES = r\"/content/drive/MyDrive/TCC/dados/dicionarios/internetes_list.csv\"\n",
        "\n",
        "# Dicionário de estados\n",
        "PATH_DICT_ESTADOS = r\"/content/drive/MyDrive/TCC/dados/dicionarios/estados_list.csv\"\n",
        "\n",
        "# Dicionário de expressões contraídas\n",
        "PATH_DICT_EXPRESSOES = r\"/content/drive/MyDrive/TCC/dados/dicionarios/dict_hate_contraidos.csv\"\n",
        "\n",
        "# Lista de vogais duplicadas\n",
        "PATH_LIST_VOGAIS_DUPLICADAS = r\"/content/drive/MyDrive/TCC/dados/dicionarios/vogais_duplicadas.csv\"\n",
        "\n",
        "# Lista de stopWords\n",
        "PATH_LIST_STOP_WORDS_PT_BR = r\"/content/drive/MyDrive/TCC/dados/dicionarios/stop_word_list.txt\"\n",
        "\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FaVkPTQ-T5gc",
        "outputId": "3fbca384-8b92-4e50-be56-5eca4ae31b08",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 337
        }
      },
      "source": [
        "#Carrega a base de dados\n",
        "baseTweets = pd.read_csv(PATH_BASE_COMPLETA_BRUTA, index_col=0)\n",
        "#baseTweets = baseTweets.sample(n=1000) #PEGANDO 1000 REGISTROS DA BASE PARA TESTE, REMOVER ISSO DEPOIS\n",
        "baseTweets.head()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                id_str                      created_at  \\\n",
              "0  1270007273088339969  Mon Jun 08 14:58:24 +0000 2020   \n",
              "1  1270005650945343489  Mon Jun 08 14:51:57 +0000 2020   \n",
              "2  1270002784742539264  Mon Jun 08 14:40:34 +0000 2020   \n",
              "3  1270001502124417025  Mon Jun 08 14:35:28 +0000 2020   \n",
              "4  1270000103416266754  Mon Jun 08 14:29:54 +0000 2020   \n",
              "\n",
              "                                                text entities.hashtags  \\\n",
              "0         @allantercalivre PARABÉNS @allantercalivre                []   \n",
              "1  RT @franciscoedi11: @allantercalivre Eu queria...                []   \n",
              "2  @allantercalivre @EdnaBraga Gostei da pulseira...                []   \n",
              "3  @allantercalivre @FBI Esses não irão ao encont...                []   \n",
              "4        @allantercalivre Cadê eles ?\\r\\nTá faltando                []   \n",
              "\n",
              "       place.full_name  \n",
              "0    Sao Paulo, Brazil  \n",
              "1                  NaN  \n",
              "2    Sao Paulo, Brazil  \n",
              "3       Recife, Brazil  \n",
              "4  Nova Iguaçu, Brasil  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7945b9c9-8467-45b4-9186-368e7d50922b\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id_str</th>\n",
              "      <th>created_at</th>\n",
              "      <th>text</th>\n",
              "      <th>entities.hashtags</th>\n",
              "      <th>place.full_name</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1270007273088339969</td>\n",
              "      <td>Mon Jun 08 14:58:24 +0000 2020</td>\n",
              "      <td>@allantercalivre PARABÉNS @allantercalivre</td>\n",
              "      <td>[]</td>\n",
              "      <td>Sao Paulo, Brazil</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1270005650945343489</td>\n",
              "      <td>Mon Jun 08 14:51:57 +0000 2020</td>\n",
              "      <td>RT @franciscoedi11: @allantercalivre Eu queria...</td>\n",
              "      <td>[]</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1270002784742539264</td>\n",
              "      <td>Mon Jun 08 14:40:34 +0000 2020</td>\n",
              "      <td>@allantercalivre @EdnaBraga Gostei da pulseira...</td>\n",
              "      <td>[]</td>\n",
              "      <td>Sao Paulo, Brazil</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1270001502124417025</td>\n",
              "      <td>Mon Jun 08 14:35:28 +0000 2020</td>\n",
              "      <td>@allantercalivre @FBI Esses não irão ao encont...</td>\n",
              "      <td>[]</td>\n",
              "      <td>Recife, Brazil</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1270000103416266754</td>\n",
              "      <td>Mon Jun 08 14:29:54 +0000 2020</td>\n",
              "      <td>@allantercalivre Cadê eles ?\\r\\nTá faltando</td>\n",
              "      <td>[]</td>\n",
              "      <td>Nova Iguaçu, Brasil</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7945b9c9-8467-45b4-9186-368e7d50922b')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-7945b9c9-8467-45b4-9186-368e7d50922b button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-7945b9c9-8467-45b4-9186-368e7d50922b');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "baseTweets.shape"
      ],
      "metadata": {
        "id": "4wkzYMsa_LcH",
        "outputId": "05654918-9fc9-4149-a750-bf2cb20abbad",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(82149, 5)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nXsmpxj_VCxY"
      },
      "source": [
        "Fase 1\n",
        "Definição das funções usadas na limpeza Etapas:\n",
        "\n",
        "1. Remover menções (Remover @fulano)\n",
        "2. Remover caracteres especiais Remover caracteres de pontuação\n",
        "3. Remover emojis\n",
        "4. Expandir internetês\n",
        "5. Normalizar nomes de estados (SP->São Paulo)\n",
        "6. Retirar letras repetidas\n",
        "7. Remover tweets com <3 tokens\n",
        "8. Remover tweets repetidos (texto idêntico)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "PADRAO_PALAVRAS_PT = r'[a-zA-Zà-úÀ-Ú]+'\n",
        "text = \"bom dia gente\"\n",
        "tokenizer = RegexpTokenizer(PADRAO_PALAVRAS_PT)\n",
        "tokens = tokenizer.tokenize(text) # Remover caracteres especiais, pontuação e emojis\n",
        "print(\"tokens\")"
      ],
      "metadata": {
        "id": "3nfgeS2K7nlc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hLDPHRyvVEsD"
      },
      "source": [
        "# Main\n",
        "\n",
        "# Carregando dicionários\n",
        "tokenizer = RegexpTokenizer(PADRAO_PALAVRAS_PT)\n",
        "dict_internetes = pd.read_csv(PATH_DICT_INTERNETES)\n",
        "dict_estados = pd.read_csv(PATH_DICT_ESTADOS)\n",
        "dict_expressoes = pd.read_csv(PATH_DICT_EXPRESSOES, encoding='latin-1')\n",
        "list_vogais_duplicadas = pd.read_csv(PATH_LIST_VOGAIS_DUPLICADAS)\n",
        "\n",
        "def pre_processamento(text):\n",
        "    # Limpeza\n",
        "    text = remover_mencao(text.lower()) # Remover menções\n",
        "    text = re.sub(r'http\\S+', '', text) # Remover links\n",
        "    tokens = tokenizer.tokenize(text) # Remover caracteres especiais, pontuação e emojis\n",
        "    tokens = expandir_sigla(tokens,dict_internetes) # Expandir Internetes\n",
        "    tokens = expandir_sigla(tokens,dict_estados) # Normalizar nomes de estado\n",
        "    tokens = remover_letras_repetidas(tokens, list_vogais_duplicadas) # Retirar letras repetidas\n",
        "    tokens = seta_tweet_pequeno_para_um(tokens) # Marca tweets pequenos\n",
        "\n",
        "    text_limpo = \" \".join(tokens)\n",
        "    return text_limpo\n",
        "\n",
        "# Remover menções   \n",
        "def remover_mencao(tweet):\n",
        "    tweet_sem_mencao = re.sub(r'[@]\\w+', '', tweet)\n",
        "    tweet_sem_mencao = \" \".join(tweet_sem_mencao.split()) # Remover espaços a mais\n",
        "    return tweet_sem_mencao\n",
        "\n",
        "# ESSA FUNÇÃO É CASE-SENSITIVE\n",
        "def expandir_sigla(tokens, dicionario):\n",
        "    colunas_dicionario = dicionario.columns\n",
        "    dicionario_py = dicionario.set_index(colunas_dicionario[0]).to_dict() # Converte Dataframe para dicionário python\n",
        "    dicionario_py = dicionario_py[colunas_dicionario[1]]\n",
        "    keys = list(dicionario_py.keys())\n",
        "\n",
        "    indice = 0\n",
        "    for token in tokens:\n",
        "      if token in keys:\n",
        "        tokens[indice] = dicionario_py[token]\n",
        "      indice+=1\n",
        "    \n",
        "    return tokens\n",
        "\n",
        "# Retirar letras repetidas\n",
        "def remover_letras_repetidas(tokens, lista):\n",
        "    lista = list(lista['vogais_duplicadas'])\n",
        "    tokens_sem_letras_repetidas = []\n",
        "    for token in tokens:\n",
        "        flag = True\n",
        "        if token not in lista: # Se for uma palavra com vogais dobradas não modifica o token\n",
        "            for i in range(len(token)):\n",
        "                # Se tiver \"rr\" ou \"ss\" não modifica o token\n",
        "                try:\n",
        "                    if (token[i].lower()=='r' and token[i+1].lower()=='r') or\\\n",
        "                        (token[i].lower()=='s' and token[i+1].lower()=='s'):\n",
        "                        flag = False\n",
        "                        break\n",
        "                except:\n",
        "                    break\n",
        "            if flag:\n",
        "                # Remove letras repetidas\n",
        "                token = ''.join(c[0] for c in itertools.groupby(token))\n",
        "        tokens_sem_letras_repetidas.append(token)\n",
        "    return tokens_sem_letras_repetidas\n",
        "\n",
        "# Marca tweets pequenos\n",
        "def seta_tweet_pequeno_para_um(tokens):\n",
        "    if len(tokens)<QUANT_TOKENS_MIN:\n",
        "        tokens = '1'\n",
        "    return tokens"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lUHrn97DYh89",
        "outputId": "3379a3a6-6d87-497e-d21b-1319f80848ae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        }
      },
      "source": [
        "# Aplicar pré processamento na base\n",
        "baseTweets['text_limpo'] = baseTweets['text'].apply(lambda x: pre_processamento(x))\n",
        "baseTweets.head()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                id_str                      created_at  \\\n",
              "0  1270007273088339969  Mon Jun 08 14:58:24 +0000 2020   \n",
              "1  1270005650945343489  Mon Jun 08 14:51:57 +0000 2020   \n",
              "2  1270002784742539264  Mon Jun 08 14:40:34 +0000 2020   \n",
              "3  1270001502124417025  Mon Jun 08 14:35:28 +0000 2020   \n",
              "4  1270000103416266754  Mon Jun 08 14:29:54 +0000 2020   \n",
              "\n",
              "                                                text entities.hashtags  \\\n",
              "0         @allantercalivre PARABÉNS @allantercalivre                []   \n",
              "1  RT @franciscoedi11: @allantercalivre Eu queria...                []   \n",
              "2  @allantercalivre @EdnaBraga Gostei da pulseira...                []   \n",
              "3  @allantercalivre @FBI Esses não irão ao encont...                []   \n",
              "4        @allantercalivre Cadê eles ?\\r\\nTá faltando                []   \n",
              "\n",
              "       place.full_name                                         text_limpo  \n",
              "0    Sao Paulo, Brazil                                                  1  \n",
              "1                  NaN  retwet eu queria compartilhar mas antes eu gos...  \n",
              "2    Sao Paulo, Brazil  gostei da pulseira e da educação dele nossaaa ...  \n",
              "3       Recife, Brazil               esses não irão ao encontro e beijing  \n",
              "4  Nova Iguaçu, Brasil                            cadê eles está faltando  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-879f4219-4ea0-4c85-bc50-e0c26a6e9259\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id_str</th>\n",
              "      <th>created_at</th>\n",
              "      <th>text</th>\n",
              "      <th>entities.hashtags</th>\n",
              "      <th>place.full_name</th>\n",
              "      <th>text_limpo</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1270007273088339969</td>\n",
              "      <td>Mon Jun 08 14:58:24 +0000 2020</td>\n",
              "      <td>@allantercalivre PARABÉNS @allantercalivre</td>\n",
              "      <td>[]</td>\n",
              "      <td>Sao Paulo, Brazil</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1270005650945343489</td>\n",
              "      <td>Mon Jun 08 14:51:57 +0000 2020</td>\n",
              "      <td>RT @franciscoedi11: @allantercalivre Eu queria...</td>\n",
              "      <td>[]</td>\n",
              "      <td>NaN</td>\n",
              "      <td>retwet eu queria compartilhar mas antes eu gos...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1270002784742539264</td>\n",
              "      <td>Mon Jun 08 14:40:34 +0000 2020</td>\n",
              "      <td>@allantercalivre @EdnaBraga Gostei da pulseira...</td>\n",
              "      <td>[]</td>\n",
              "      <td>Sao Paulo, Brazil</td>\n",
              "      <td>gostei da pulseira e da educação dele nossaaa ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1270001502124417025</td>\n",
              "      <td>Mon Jun 08 14:35:28 +0000 2020</td>\n",
              "      <td>@allantercalivre @FBI Esses não irão ao encont...</td>\n",
              "      <td>[]</td>\n",
              "      <td>Recife, Brazil</td>\n",
              "      <td>esses não irão ao encontro e beijing</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1270000103416266754</td>\n",
              "      <td>Mon Jun 08 14:29:54 +0000 2020</td>\n",
              "      <td>@allantercalivre Cadê eles ?\\r\\nTá faltando</td>\n",
              "      <td>[]</td>\n",
              "      <td>Nova Iguaçu, Brasil</td>\n",
              "      <td>cadê eles está faltando</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-879f4219-4ea0-4c85-bc50-e0c26a6e9259')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-879f4219-4ea0-4c85-bc50-e0c26a6e9259 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-879f4219-4ea0-4c85-bc50-e0c26a6e9259');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Remover tweets marcados como pequenos e remove tweets repetidos(texto idêntico) \n",
        "baseTweets.drop_duplicates(subset='text_limpo', keep='first', inplace=True)\n",
        "\n",
        "# apaga a linha com o texto = '1' que sobra\n",
        "baseTweets = baseTweets[baseTweets['text_limpo']!='1']\n"
      ],
      "metadata": {
        "id": "6LCOpBVk8SHs"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Porque está diminuindo quando rodamos mais de uma vez ?\n",
        "baseTweets.shape"
      ],
      "metadata": {
        "id": "BB4RWsuA_PPG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6ee94def-e0a4-4993-f984-b45ebb1558e7"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(73579, 6)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yFZz24V3Fecx"
      },
      "source": [
        "baseTweets.to_csv('/content/drive/MyDrive/TCC/dados/processadas/Base1_Com_StopWords.csv') #Salva base limpa"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oTxagMLGFCo_"
      },
      "source": [
        "Fase 2\n",
        "remover stopswords"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eWB-wfr8YqqZ",
        "outputId": "c9f49511-5fc5-4dbd-ace3-8afd610fc513",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 183
        }
      },
      "source": [
        "# O arquivo \"portuguese\" contem Stopwords em Portugues\n",
        "Sw = open(PATH_LIST_STOP_WORDS_PT_BR,'r',encoding='utf-8')\n",
        "ptBr_stopwords = Sw.read()\n",
        "ptBr_stopwords"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\ufeffde\\na\\no\\ne\\ndo\\nda\\nem\\num\\npara\\ncom\\nnão\\numa\\nos\\nno\\nse\\nna\\npor\\nmais\\nas\\ndos\\ncomo\\nmas\\nao\\nele\\ndas\\nà\\nseu\\nsua\\nou\\nquando\\nmuito\\nnos\\njá\\neu\\ntambém\\nsó\\npelo\\npela\\naté\\nisso\\nela\\nentre\\ndepois\\nsem\\nmesmo\\naos\\nseus\\nquem\\nnas\\nme\\nesse\\neles\\nvocê\\nessa\\nnum\\nnem\\nsuas\\nmeu\\nàs\\nminha\\nnuma\\npelos\\nelas\\nqual\\nnós\\nlhe\\ndeles\\nessas\\nesses\\npelas\\neste\\ndele\\ntu\\nte\\nvocês\\nvos\\nlhes\\nmeus\\nminhas\\nteu\\ntua\\nteus\\ntuas\\nnosso\\nnossa\\nnossos\\nnossas\\ndela\\ndelas\\nesta\\nestes\\nestas\\naquele\\naquela\\naqueles\\naquelas\\nisto\\naquilo\\nestou\\nestá\\nestamos\\nestão\\nestive\\nesteve\\nestivemos\\nestiveram\\nestava\\nestávamos\\nestavam\\nestivera\\nestivéramos\\nesteja\\nestejamos\\nestejam\\nestivesse\\nestivéssemos\\nestivessem\\nestiver\\nestivermos\\nestiverem\\nhei\\nhá\\nhavemos\\nhão\\nhouve\\nhouvemos\\nhouveram\\nhouvera\\nhouvéramos\\nhaja\\nhajamos\\nhajam\\nhouvesse\\nhouvéssemos\\nhouvessem\\nhouver\\nhouvermos\\nhouverem\\nhouverei\\nhouverá\\nhouveremos\\nhouverão\\nhouveria\\nhouveríamos\\nhouveriam\\nsou\\nsomos\\nsão\\nera\\néramos\\neram\\nfui\\nfoi\\nfomos\\nforam\\nfora\\nfôramos\\nseja\\nsejamos\\nsejam\\nfosse\\nfôssemos\\nfossem\\nfor\\nformos\\nforem\\nserei\\nserá\\nseremos\\nserão\\nseria\\nseríamos\\nseriam\\ntenho\\ntem\\ntemos\\ntém\\ntinha\\ntínhamos\\ntinham\\ntive\\nteve\\ntivemos\\ntiveram\\ntivera\\ntivéramos\\ntenha\\ntenhamos\\ntenham\\ntivesse\\ntivéssemos\\ntivessem\\ntiver\\ntivermos\\ntiverem\\nterei\\nterá\\nteremos\\nterão\\nteria\\nteríamos\\nteriam\\nnunca\\nalgumas\\nalguma\\nhoje\\nvai\\nsobre\\nmenos\\nmais\\nmas\\nporque\\nporquê\\npor\\nque\\nquê \\nmaior\\nquase\\nprimeiro\\nprimeira\\nanos\\nano\\ndia\\ndias\\nvotos\\nvoto\\ntodo\\ntodos\\ntoda\\ntodas\\nDe\\nA\\nO\\nE\\nDo\\nDa\\nEm\\nUm\\nPara\\nCom\\nNão\\nUma\\nOs\\nNo\\nSe\\nNa\\nPor\\nMais\\nAs\\nDos\\nComo\\nMas\\nAo\\nEle\\nDas\\nÀ\\nSeu\\nSua\\nOu\\nQuando\\nMuito\\nNos\\nJá\\nEu\\nTambém\\nSó\\nPelo\\nPela\\nAté\\nIsso\\nEla\\nEntre\\nDepois\\nSem\\nMesmo\\nAos\\nSeus\\nQuem\\nNas\\nMe\\nEsse\\nEles\\nVocê\\nEssa\\nNum\\nNem\\nSuas\\nMeu\\nÀs\\nMinha\\nNuma\\nPelos\\nElas\\nQual\\nNós\\nLhe\\nDeles\\nEssas\\nEsses\\nPelas\\nEste\\nDele\\nTu\\nTe\\nVocês\\nVos\\nLhes\\nMeus\\nMinhas\\nTeu\\nTua\\nTeus\\nTuas\\nNosso\\nNossa\\nNossos\\nNossas\\nDela\\nDelas\\nEsta\\nEstes\\nEstas\\nAquele\\nAquela\\nAqueles\\nAquelas\\nIsto\\nAquilo\\nEstou\\nEstá\\nEstamos\\nEstão\\nEstive\\nEsteve\\nEstivemos\\nEstiveram\\nEstava\\nEstávamos\\nEstavam\\nEstivera\\nEstivéramos\\nEsteja\\nEstejamos\\nEstejam\\nEstivesse\\nEstivéssemos\\nEstivessem\\nEstiver\\nEstivermos\\nEstiverem\\nHei\\nHá\\nHavemos\\nHão\\nHouve\\nHouvemos\\nHouveram\\nHouvera\\nHouvéramos\\nHaja\\nHajamos\\nHajam\\nHouvesse\\nHouvéssemos\\nHouvessem\\nHouver\\nHouvermos\\nHouverem\\nHouverei\\nHouverá\\nHouveremos\\nHouverão\\nHouveria\\nHouveríamos\\nHouveriam\\nSou\\nSomos\\nEra\\nÉramos\\nEram\\nFui\\nFoi\\nFomos\\nForam\\nFora\\nFôramos\\nSeja\\nSejamos\\nSejam\\nFosse\\nFôssemos\\nFossem\\nFor\\nFormos\\nForem\\nSerei\\nSerá\\nSeremos\\nSerão\\nSeria\\nSeríamos\\nSeriam\\nTenho\\nTem\\nTemos\\nTém\\nTinha\\nTínhamos\\nTinham\\nTive\\nTeve\\nTivemos\\nTiveram\\nTivera\\nTivéramos\\nTenha\\nTenhamos\\nTenham\\nTivesse\\nTivéssemos\\nTivessem\\nTiver\\nTivermos\\nTiverem\\nTerei\\nTerá\\nTeremos\\nTerão\\nTeria\\nTeríamos\\nTeriam\\nNunca\\nAlgumas\\nAlguma\\nHoje\\nVai\\nSobre\\nMenos\\nMais\\nMas\\nPorque\\nPorquê\\nPor\\nQue\\nQuê\\nMaior\\nQuase\\nPrimeiro\\nPrimeira\\nAnos\\nAno\\nDia\\nDias\\nVotos\\nVoto\\nTodo\\nTodos\\nToda\\nTodas'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open(PATH_LIST_STOP_WORDS_PT_BR,'r',encoding='utf-8') as Sw:\n",
        "  lines = Sw.readlines()\n",
        "print(lines)"
      ],
      "metadata": {
        "id": "jF4_lSrOwO1Z",
        "outputId": "3ba001ec-f863-4686-95e7-4c436a99ff58",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['\\ufeffde\\n', 'a\\n', 'o\\n', 'e\\n', 'do\\n', 'da\\n', 'em\\n', 'um\\n', 'para\\n', 'com\\n', 'não\\n', 'uma\\n', 'os\\n', 'no\\n', 'se\\n', 'na\\n', 'por\\n', 'mais\\n', 'as\\n', 'dos\\n', 'como\\n', 'mas\\n', 'ao\\n', 'ele\\n', 'das\\n', 'à\\n', 'seu\\n', 'sua\\n', 'ou\\n', 'quando\\n', 'muito\\n', 'nos\\n', 'já\\n', 'eu\\n', 'também\\n', 'só\\n', 'pelo\\n', 'pela\\n', 'até\\n', 'isso\\n', 'ela\\n', 'entre\\n', 'depois\\n', 'sem\\n', 'mesmo\\n', 'aos\\n', 'seus\\n', 'quem\\n', 'nas\\n', 'me\\n', 'esse\\n', 'eles\\n', 'você\\n', 'essa\\n', 'num\\n', 'nem\\n', 'suas\\n', 'meu\\n', 'às\\n', 'minha\\n', 'numa\\n', 'pelos\\n', 'elas\\n', 'qual\\n', 'nós\\n', 'lhe\\n', 'deles\\n', 'essas\\n', 'esses\\n', 'pelas\\n', 'este\\n', 'dele\\n', 'tu\\n', 'te\\n', 'vocês\\n', 'vos\\n', 'lhes\\n', 'meus\\n', 'minhas\\n', 'teu\\n', 'tua\\n', 'teus\\n', 'tuas\\n', 'nosso\\n', 'nossa\\n', 'nossos\\n', 'nossas\\n', 'dela\\n', 'delas\\n', 'esta\\n', 'estes\\n', 'estas\\n', 'aquele\\n', 'aquela\\n', 'aqueles\\n', 'aquelas\\n', 'isto\\n', 'aquilo\\n', 'estou\\n', 'está\\n', 'estamos\\n', 'estão\\n', 'estive\\n', 'esteve\\n', 'estivemos\\n', 'estiveram\\n', 'estava\\n', 'estávamos\\n', 'estavam\\n', 'estivera\\n', 'estivéramos\\n', 'esteja\\n', 'estejamos\\n', 'estejam\\n', 'estivesse\\n', 'estivéssemos\\n', 'estivessem\\n', 'estiver\\n', 'estivermos\\n', 'estiverem\\n', 'hei\\n', 'há\\n', 'havemos\\n', 'hão\\n', 'houve\\n', 'houvemos\\n', 'houveram\\n', 'houvera\\n', 'houvéramos\\n', 'haja\\n', 'hajamos\\n', 'hajam\\n', 'houvesse\\n', 'houvéssemos\\n', 'houvessem\\n', 'houver\\n', 'houvermos\\n', 'houverem\\n', 'houverei\\n', 'houverá\\n', 'houveremos\\n', 'houverão\\n', 'houveria\\n', 'houveríamos\\n', 'houveriam\\n', 'sou\\n', 'somos\\n', 'são\\n', 'era\\n', 'éramos\\n', 'eram\\n', 'fui\\n', 'foi\\n', 'fomos\\n', 'foram\\n', 'fora\\n', 'fôramos\\n', 'seja\\n', 'sejamos\\n', 'sejam\\n', 'fosse\\n', 'fôssemos\\n', 'fossem\\n', 'for\\n', 'formos\\n', 'forem\\n', 'serei\\n', 'será\\n', 'seremos\\n', 'serão\\n', 'seria\\n', 'seríamos\\n', 'seriam\\n', 'tenho\\n', 'tem\\n', 'temos\\n', 'tém\\n', 'tinha\\n', 'tínhamos\\n', 'tinham\\n', 'tive\\n', 'teve\\n', 'tivemos\\n', 'tiveram\\n', 'tivera\\n', 'tivéramos\\n', 'tenha\\n', 'tenhamos\\n', 'tenham\\n', 'tivesse\\n', 'tivéssemos\\n', 'tivessem\\n', 'tiver\\n', 'tivermos\\n', 'tiverem\\n', 'terei\\n', 'terá\\n', 'teremos\\n', 'terão\\n', 'teria\\n', 'teríamos\\n', 'teriam\\n', 'nunca\\n', 'algumas\\n', 'alguma\\n', 'hoje\\n', 'vai\\n', 'sobre\\n', 'menos\\n', 'mais\\n', 'mas\\n', 'porque\\n', 'porquê\\n', 'por\\n', 'que\\n', 'quê \\n', 'maior\\n', 'quase\\n', 'primeiro\\n', 'primeira\\n', 'anos\\n', 'ano\\n', 'dia\\n', 'dias\\n', 'votos\\n', 'voto\\n', 'todo\\n', 'todos\\n', 'toda\\n', 'todas\\n', 'De\\n', 'A\\n', 'O\\n', 'E\\n', 'Do\\n', 'Da\\n', 'Em\\n', 'Um\\n', 'Para\\n', 'Com\\n', 'Não\\n', 'Uma\\n', 'Os\\n', 'No\\n', 'Se\\n', 'Na\\n', 'Por\\n', 'Mais\\n', 'As\\n', 'Dos\\n', 'Como\\n', 'Mas\\n', 'Ao\\n', 'Ele\\n', 'Das\\n', 'À\\n', 'Seu\\n', 'Sua\\n', 'Ou\\n', 'Quando\\n', 'Muito\\n', 'Nos\\n', 'Já\\n', 'Eu\\n', 'Também\\n', 'Só\\n', 'Pelo\\n', 'Pela\\n', 'Até\\n', 'Isso\\n', 'Ela\\n', 'Entre\\n', 'Depois\\n', 'Sem\\n', 'Mesmo\\n', 'Aos\\n', 'Seus\\n', 'Quem\\n', 'Nas\\n', 'Me\\n', 'Esse\\n', 'Eles\\n', 'Você\\n', 'Essa\\n', 'Num\\n', 'Nem\\n', 'Suas\\n', 'Meu\\n', 'Às\\n', 'Minha\\n', 'Numa\\n', 'Pelos\\n', 'Elas\\n', 'Qual\\n', 'Nós\\n', 'Lhe\\n', 'Deles\\n', 'Essas\\n', 'Esses\\n', 'Pelas\\n', 'Este\\n', 'Dele\\n', 'Tu\\n', 'Te\\n', 'Vocês\\n', 'Vos\\n', 'Lhes\\n', 'Meus\\n', 'Minhas\\n', 'Teu\\n', 'Tua\\n', 'Teus\\n', 'Tuas\\n', 'Nosso\\n', 'Nossa\\n', 'Nossos\\n', 'Nossas\\n', 'Dela\\n', 'Delas\\n', 'Esta\\n', 'Estes\\n', 'Estas\\n', 'Aquele\\n', 'Aquela\\n', 'Aqueles\\n', 'Aquelas\\n', 'Isto\\n', 'Aquilo\\n', 'Estou\\n', 'Está\\n', 'Estamos\\n', 'Estão\\n', 'Estive\\n', 'Esteve\\n', 'Estivemos\\n', 'Estiveram\\n', 'Estava\\n', 'Estávamos\\n', 'Estavam\\n', 'Estivera\\n', 'Estivéramos\\n', 'Esteja\\n', 'Estejamos\\n', 'Estejam\\n', 'Estivesse\\n', 'Estivéssemos\\n', 'Estivessem\\n', 'Estiver\\n', 'Estivermos\\n', 'Estiverem\\n', 'Hei\\n', 'Há\\n', 'Havemos\\n', 'Hão\\n', 'Houve\\n', 'Houvemos\\n', 'Houveram\\n', 'Houvera\\n', 'Houvéramos\\n', 'Haja\\n', 'Hajamos\\n', 'Hajam\\n', 'Houvesse\\n', 'Houvéssemos\\n', 'Houvessem\\n', 'Houver\\n', 'Houvermos\\n', 'Houverem\\n', 'Houverei\\n', 'Houverá\\n', 'Houveremos\\n', 'Houverão\\n', 'Houveria\\n', 'Houveríamos\\n', 'Houveriam\\n', 'Sou\\n', 'Somos\\n', 'Era\\n', 'Éramos\\n', 'Eram\\n', 'Fui\\n', 'Foi\\n', 'Fomos\\n', 'Foram\\n', 'Fora\\n', 'Fôramos\\n', 'Seja\\n', 'Sejamos\\n', 'Sejam\\n', 'Fosse\\n', 'Fôssemos\\n', 'Fossem\\n', 'For\\n', 'Formos\\n', 'Forem\\n', 'Serei\\n', 'Será\\n', 'Seremos\\n', 'Serão\\n', 'Seria\\n', 'Seríamos\\n', 'Seriam\\n', 'Tenho\\n', 'Tem\\n', 'Temos\\n', 'Tém\\n', 'Tinha\\n', 'Tínhamos\\n', 'Tinham\\n', 'Tive\\n', 'Teve\\n', 'Tivemos\\n', 'Tiveram\\n', 'Tivera\\n', 'Tivéramos\\n', 'Tenha\\n', 'Tenhamos\\n', 'Tenham\\n', 'Tivesse\\n', 'Tivéssemos\\n', 'Tivessem\\n', 'Tiver\\n', 'Tivermos\\n', 'Tiverem\\n', 'Terei\\n', 'Terá\\n', 'Teremos\\n', 'Terão\\n', 'Teria\\n', 'Teríamos\\n', 'Teriam\\n', 'Nunca\\n', 'Algumas\\n', 'Alguma\\n', 'Hoje\\n', 'Vai\\n', 'Sobre\\n', 'Menos\\n', 'Mais\\n', 'Mas\\n', 'Porque\\n', 'Porquê\\n', 'Por\\n', 'Que\\n', 'Quê\\n', 'Maior\\n', 'Quase\\n', 'Primeiro\\n', 'Primeira\\n', 'Anos\\n', 'Ano\\n', 'Dia\\n', 'Dias\\n', 'Votos\\n', 'Voto\\n', 'Todo\\n', 'Todos\\n', 'Toda\\n', 'Todas']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "[line.lower().split() for line in lines]"
      ],
      "metadata": {
        "id": "hEZQuzBaxg6p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J4ut0uAnFMjB",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 337
        },
        "outputId": "45fbc7b4-38a9-4e1d-b2f7-91c2e6580e6d"
      },
      "source": [
        "baseTweets['text_cleanStopWords'] = baseTweets['text_limpo'].apply(lambda x: ' '.join([word for word in x.split() if word not in (ptBr_stopwords)]))\n",
        "baseTweets.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-362cf40f-8ac6-4df1-9e3d-4cdd5d812275\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id_str</th>\n",
              "      <th>created_at</th>\n",
              "      <th>text</th>\n",
              "      <th>entities.hashtags</th>\n",
              "      <th>place.full_name</th>\n",
              "      <th>text_limpo</th>\n",
              "      <th>text_cleanStopWords</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1270005650945343489</td>\n",
              "      <td>Mon Jun 08 14:51:57 +0000 2020</td>\n",
              "      <td>RT @franciscoedi11: @allantercalivre Eu queria...</td>\n",
              "      <td>[]</td>\n",
              "      <td>NaN</td>\n",
              "      <td>retwet eu queria compartilhar mas antes eu gos...</td>\n",
              "      <td>retwet queria compartilhar antes gostaria sabe...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1270002784742539264</td>\n",
              "      <td>Mon Jun 08 14:40:34 +0000 2020</td>\n",
              "      <td>@allantercalivre @EdnaBraga Gostei da pulseira...</td>\n",
              "      <td>[]</td>\n",
              "      <td>Sao Paulo, Brazil</td>\n",
              "      <td>gostei da pulseira e da educação dele nossaaa ...</td>\n",
              "      <td>gostei pulseira educação nossaaa muita elegânc...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1270001502124417025</td>\n",
              "      <td>Mon Jun 08 14:35:28 +0000 2020</td>\n",
              "      <td>@allantercalivre @FBI Esses não irão ao encont...</td>\n",
              "      <td>[]</td>\n",
              "      <td>Recife, Brazil</td>\n",
              "      <td>esses não irão ao encontro e beijing</td>\n",
              "      <td>irão encontro beijing</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>1269998146601529344</td>\n",
              "      <td>Mon Jun 08 14:22:08 +0000 2020</td>\n",
              "      <td>@allantercalivre e eu me questionando:  “quem ...</td>\n",
              "      <td>[]</td>\n",
              "      <td>Mossoró, Brasil</td>\n",
              "      <td>e eu me questionando quem é esse blogueiro sem...</td>\n",
              "      <td>questionando blogueiro blog juntos</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>1269997249746087939</td>\n",
              "      <td>Mon Jun 08 14:18:34 +0000 2020</td>\n",
              "      <td>@allantercalivre @marciolabre @jairbolsonaro R...</td>\n",
              "      <td>[]</td>\n",
              "      <td>Uberlândia, Brasil</td>\n",
              "      <td>renan caloteiro desonesto vejam link abaixo</td>\n",
              "      <td>renan caloteiro desonesto vejam link abaixo</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-362cf40f-8ac6-4df1-9e3d-4cdd5d812275')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-362cf40f-8ac6-4df1-9e3d-4cdd5d812275 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-362cf40f-8ac6-4df1-9e3d-4cdd5d812275');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                id_str                      created_at  \\\n",
              "1  1270005650945343489  Mon Jun 08 14:51:57 +0000 2020   \n",
              "2  1270002784742539264  Mon Jun 08 14:40:34 +0000 2020   \n",
              "3  1270001502124417025  Mon Jun 08 14:35:28 +0000 2020   \n",
              "5  1269998146601529344  Mon Jun 08 14:22:08 +0000 2020   \n",
              "6  1269997249746087939  Mon Jun 08 14:18:34 +0000 2020   \n",
              "\n",
              "                                                text entities.hashtags  \\\n",
              "1  RT @franciscoedi11: @allantercalivre Eu queria...                []   \n",
              "2  @allantercalivre @EdnaBraga Gostei da pulseira...                []   \n",
              "3  @allantercalivre @FBI Esses não irão ao encont...                []   \n",
              "5  @allantercalivre e eu me questionando:  “quem ...                []   \n",
              "6  @allantercalivre @marciolabre @jairbolsonaro R...                []   \n",
              "\n",
              "      place.full_name                                         text_limpo  \\\n",
              "1                 NaN  retwet eu queria compartilhar mas antes eu gos...   \n",
              "2   Sao Paulo, Brazil  gostei da pulseira e da educação dele nossaaa ...   \n",
              "3      Recife, Brazil               esses não irão ao encontro e beijing   \n",
              "5     Mossoró, Brasil  e eu me questionando quem é esse blogueiro sem...   \n",
              "6  Uberlândia, Brasil        renan caloteiro desonesto vejam link abaixo   \n",
              "\n",
              "                                 text_cleanStopWords  \n",
              "1  retwet queria compartilhar antes gostaria sabe...  \n",
              "2  gostei pulseira educação nossaaa muita elegânc...  \n",
              "3                              irão encontro beijing  \n",
              "5                 questionando blogueiro blog juntos  \n",
              "6        renan caloteiro desonesto vejam link abaixo  "
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Seta os tweets pequenos (<3) da coluna sem stop words para 1\n",
        "baseTweets[\"text_cleanStopWords2\"] = baseTweets[\"text_cleanStopWords\"].apply(lambda x: ' '.join(seta_tweet_pequeno_para_um(x.split())))"
      ],
      "metadata": {
        "id": "lJQzEf291_gk"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Remover tweets marcados como pequenos e remove tweets repetidos(texto idêntico) \n",
        "baseTweets.drop_duplicates(subset='text_cleanStopWords2', keep='first', inplace=True)\n",
        "\n",
        "# apaga a linha com o texto = '1' que sobra\n",
        "baseTweets = baseTweets[baseTweets['text_cleanStopWords2']!='1']"
      ],
      "metadata": {
        "id": "slY5Ysqz2x0J"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "baseTweets.shape()"
      ],
      "metadata": {
        "id": "TdiAR7Zk4vfc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dropa colunas\n",
        "baseTweets.drop(['text_limpo','text_cleanStopWords'], axis='columns', inplace=True)\n",
        "\n",
        "# Renomeia as colunas que sobraram\n",
        "baseTweets.rename(columns = {'text_cleanStopWords2': 'text_limpo', 'classificacao_hate': 'label'}, inplace = True)\n",
        "baseTweets.head(5)"
      ],
      "metadata": {
        "id": "DyeZUqzq4Y1j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4FsVbVhzFNJw"
      },
      "source": [
        "baseTweets.to_csv('/content/drive/MyDrive/TCC/dados/processadas/Base2_Sem_StopWords.csv') #Salva base limpa"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}