{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Treinamento-NaiveBayes.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LuanPCunha/TCC/blob/main/Treinamento_NaiveBayes.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Imports e definições de funções"
      ],
      "metadata": {
        "id": "EvS_6l_yMUeH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install tensorflow\n",
        "# !pip install keras"
      ],
      "metadata": {
        "id": "N5Vhr4_vECld"
      },
      "execution_count": 131,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ptoQwAGEDQnl",
        "outputId": "d1b4fbcb-fcb5-46b3-fc95-591aa724736a"
      },
      "execution_count": 132,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import string, re\n",
        "import itertools\n",
        "import nltk\n",
        "import plotly.offline as py\n",
        "import plotly.graph_objs as go\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import accuracy_score\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Embedding, LSTM\n",
        "from keras.callbacks import EarlyStopping\n",
        "py.init_notebook_mode(connected=True)\n",
        "%matplotlib inline\n",
        "from sklearn import model_selection, preprocessing, linear_model, naive_bayes, metrics, svm\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
        "from sklearn import decomposition, ensemble\n",
        "import pandas, xgboost, numpy, textblob, string\n",
        "from keras.preprocessing import text, sequence\n",
        "from keras import layers, models, optimizers\n",
        "import math\n",
        "from sklearn.metrics import roc_auc_score, roc_curve, confusion_matrix\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "from mlxtend.plotting import plot_confusion_matrix"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "YYGxUH68sUuH",
        "outputId": "ffc8fcdc-e364-43de-d4b5-4e52c87839a7"
      },
      "execution_count": 163,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "        <script type=\"text/javascript\">\n",
              "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
              "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
              "        if (typeof require !== 'undefined') {\n",
              "        require.undef(\"plotly\");\n",
              "        requirejs.config({\n",
              "            paths: {\n",
              "                'plotly': ['https://cdn.plot.ly/plotly-2.8.3.min']\n",
              "            }\n",
              "        });\n",
              "        require(['plotly'], function(Plotly) {\n",
              "            window._Plotly = Plotly;\n",
              "        });\n",
              "        }\n",
              "        </script>\n",
              "        "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize(tweets_list):\n",
        "    tokenizer = Tokenizer()\n",
        "    tokenizer.fit_on_texts(tweets_list)\n",
        "    return tokenizer.texts_to_sequences(tweets_list), tokenizer"
      ],
      "metadata": {
        "id": "db4KNc_2Ixyu"
      },
      "execution_count": 134,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def pad(text_tokenized, length=None):\n",
        "    return pad_sequences(text_tokenized, maxlen=length, padding='post')"
      ],
      "metadata": {
        "id": "pwcjgZd9I6AD"
      },
      "execution_count": 135,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess(tweets_list, max_text_length):\n",
        "   \n",
        "    preprocess_tweets_list, tweets_list_tokenizer = tokenize(tweets_list)\n",
        "\n",
        "    preprocess_tweets_list = pad(preprocess_tweets_list, length=max_text_length)\n",
        "\n",
        "    return preprocess_tweets_list, tweets_list_tokenizer"
      ],
      "metadata": {
        "id": "fNMyJgcsI8AU"
      },
      "execution_count": 136,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# CONSTANTES DOS RESULTADOS\n",
        "REDE = 'NaiveBayes'\n",
        "\n",
        "BASE_NAME = 'BASE 0'\n",
        "# BASE_NAME = 'BASE 1'\n",
        "# BASE_NAME = 'BASE 2'\n",
        "\n",
        "# Caminho arquivo de saída\n",
        "PATH_ARQ_SAIDA = \"/content/drive/MyDrive/TCC/resultados/resultados.csv\"\n",
        "\n",
        "#  rede base otimizador acuracia val_loss learning_rate dropout batch_size roc_curve train_resume confusion_matrix\n",
        "resultados = pd.read_csv(PATH_ARQ_SAIDA, index_col=0)\n",
        "resultados"
      ],
      "metadata": {
        "id": "gRUri2aOcxEZ",
        "outputId": "495ac2bc-f5ae-4eaa-c0da-6b433d70c01f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 641
        }
      },
      "execution_count": 137,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "           rede    base otimizador  acuracia    val_loss  learning_rate  \\\n",
              "0       Bi-LSTM  BASE 0      Nadam  0.864151    0.359641         0.0001   \n",
              "1       Bi-LSTM  BASE 0      Nadam  0.876550    0.302028         0.0001   \n",
              "2       Bi-LSTM  BASE 0      Nadam  0.864151    0.318839         0.0001   \n",
              "3       Bi-LSTM  BASE 0    RMSProp  0.852291    0.325597         0.0001   \n",
              "4       Bi-LSTM  BASE 0    RMSProp  0.852291    0.327882         0.0001   \n",
              "..          ...     ...        ...       ...         ...            ...   \n",
              "355  ShallowNet  BASE 2    RMSProp  0.509202  175.864090         0.0001   \n",
              "356  ShallowNet  BASE 2        SGD  0.500000   82.666985         0.0001   \n",
              "357  ShallowNet  BASE 2      Nadam  0.496933  135.945312         0.0010   \n",
              "358  ShallowNet  BASE 2    RMSProp  0.516360  121.295631         0.0010   \n",
              "359  ShallowNet  BASE 2        SGD  0.536810    4.673399         0.0010   \n",
              "\n",
              "     dropout  batch_size                                          roc_curve  \\\n",
              "0        0.1          32  {\"false_positive_rate\": [0.0, 0.0, 0.0, 0.0, 0...   \n",
              "1        0.2          32  {\"false_positive_rate\": [0.0, 0.0, 0.0, 0.0, 0...   \n",
              "2        0.3          32  {\"false_positive_rate\": [0.0, 0.0, 0.0, 0.0, 0...   \n",
              "3        0.1          32  {\"false_positive_rate\": [0.0, 0.0, 0.0, 0.0, 0...   \n",
              "4        0.2          32  {\"false_positive_rate\": [0.0, 0.0, 0.0, 0.0, 0...   \n",
              "..       ...         ...                                                ...   \n",
              "355      0.0          64  {\"false_positive_rate\": [0.0, 0.30061349693251...   \n",
              "356      0.0          64  {\"false_positive_rate\": [0.0, 0.0, 0.006134969...   \n",
              "357      0.0          64  {\"false_positive_rate\": [0.0, 0.25766871165644...   \n",
              "358      0.0          64  {\"false_positive_rate\": [0.0, 0.31901840490797...   \n",
              "359      0.0          64  {\"false_positive_rate\": [0.0, 0.02453987730061...   \n",
              "\n",
              "                                          train_resume  \\\n",
              "0    {\"epoch\": {\"0\": 0, \"1\": 1, \"2\": 2, \"3\": 3}, \"a...   \n",
              "1    {\"epoch\": {\"0\": 0, \"1\": 1, \"2\": 2, \"3\": 3}, \"a...   \n",
              "2    {\"epoch\": {\"0\": 0, \"1\": 1, \"2\": 2, \"3\": 3}, \"a...   \n",
              "3    {\"epoch\": {\"0\": 0, \"1\": 1, \"2\": 2, \"3\": 3}, \"a...   \n",
              "4    {\"epoch\": {\"0\": 0, \"1\": 1, \"2\": 2, \"3\": 3}, \"a...   \n",
              "..                                                 ...   \n",
              "355  {\"epoch\": {\"0\": 0, \"1\": 1, \"2\": 2, \"3\": 3, \"4\"...   \n",
              "356  {\"epoch\": {\"0\": 0, \"1\": 1}, \"accuracy\": {\"0\": ...   \n",
              "357  {\"epoch\": {\"0\": 0, \"1\": 1}, \"accuracy\": {\"0\": ...   \n",
              "358  {\"epoch\": {\"0\": 0, \"1\": 1}, \"accuracy\": {\"0\": ...   \n",
              "359  {\"epoch\": {\"0\": 0, \"1\": 1}, \"accuracy\": {\"0\": ...   \n",
              "\n",
              "                                 confusion_matrix  epochs      rank  \n",
              "0     {\"00\": 855, \"01\": 73, \"10\": 179, \"11\": 748}       4  2.402818  \n",
              "1    {\"00\": 803, \"01\": 125, \"10\": 104, \"11\": 823}       4  2.902218  \n",
              "2    {\"00\": 802, \"01\": 126, \"10\": 126, \"11\": 801}       4  2.710301  \n",
              "3    {\"00\": 800, \"01\": 128, \"10\": 146, \"11\": 781}       4  2.617622  \n",
              "4     {\"00\": 838, \"01\": 90, \"10\": 184, \"11\": 743}       4  2.599382  \n",
              "..                                            ...     ...       ...  \n",
              "355  {\"00\": 323, \"01\": 166, \"10\": 314, \"11\": 175}       5  0.002895  \n",
              "356      {\"00\": 486, \"01\": 3, \"10\": 486, \"11\": 3}       2  0.006048  \n",
              "357  {\"00\": 329, \"01\": 160, \"10\": 332, \"11\": 157}       2  0.003655  \n",
              "358  {\"00\": 290, \"01\": 199, \"10\": 274, \"11\": 215}       2  0.004257  \n",
              "359  {\"00\": 263, \"01\": 226, \"10\": 227, \"11\": 262}       2  0.114865  \n",
              "\n",
              "[360 rows x 13 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-9d0f9926-e08f-48b0-9036-736c48b2d2c3\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>rede</th>\n",
              "      <th>base</th>\n",
              "      <th>otimizador</th>\n",
              "      <th>acuracia</th>\n",
              "      <th>val_loss</th>\n",
              "      <th>learning_rate</th>\n",
              "      <th>dropout</th>\n",
              "      <th>batch_size</th>\n",
              "      <th>roc_curve</th>\n",
              "      <th>train_resume</th>\n",
              "      <th>confusion_matrix</th>\n",
              "      <th>epochs</th>\n",
              "      <th>rank</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Bi-LSTM</td>\n",
              "      <td>BASE 0</td>\n",
              "      <td>Nadam</td>\n",
              "      <td>0.864151</td>\n",
              "      <td>0.359641</td>\n",
              "      <td>0.0001</td>\n",
              "      <td>0.1</td>\n",
              "      <td>32</td>\n",
              "      <td>{\"false_positive_rate\": [0.0, 0.0, 0.0, 0.0, 0...</td>\n",
              "      <td>{\"epoch\": {\"0\": 0, \"1\": 1, \"2\": 2, \"3\": 3}, \"a...</td>\n",
              "      <td>{\"00\": 855, \"01\": 73, \"10\": 179, \"11\": 748}</td>\n",
              "      <td>4</td>\n",
              "      <td>2.402818</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Bi-LSTM</td>\n",
              "      <td>BASE 0</td>\n",
              "      <td>Nadam</td>\n",
              "      <td>0.876550</td>\n",
              "      <td>0.302028</td>\n",
              "      <td>0.0001</td>\n",
              "      <td>0.2</td>\n",
              "      <td>32</td>\n",
              "      <td>{\"false_positive_rate\": [0.0, 0.0, 0.0, 0.0, 0...</td>\n",
              "      <td>{\"epoch\": {\"0\": 0, \"1\": 1, \"2\": 2, \"3\": 3}, \"a...</td>\n",
              "      <td>{\"00\": 803, \"01\": 125, \"10\": 104, \"11\": 823}</td>\n",
              "      <td>4</td>\n",
              "      <td>2.902218</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Bi-LSTM</td>\n",
              "      <td>BASE 0</td>\n",
              "      <td>Nadam</td>\n",
              "      <td>0.864151</td>\n",
              "      <td>0.318839</td>\n",
              "      <td>0.0001</td>\n",
              "      <td>0.3</td>\n",
              "      <td>32</td>\n",
              "      <td>{\"false_positive_rate\": [0.0, 0.0, 0.0, 0.0, 0...</td>\n",
              "      <td>{\"epoch\": {\"0\": 0, \"1\": 1, \"2\": 2, \"3\": 3}, \"a...</td>\n",
              "      <td>{\"00\": 802, \"01\": 126, \"10\": 126, \"11\": 801}</td>\n",
              "      <td>4</td>\n",
              "      <td>2.710301</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Bi-LSTM</td>\n",
              "      <td>BASE 0</td>\n",
              "      <td>RMSProp</td>\n",
              "      <td>0.852291</td>\n",
              "      <td>0.325597</td>\n",
              "      <td>0.0001</td>\n",
              "      <td>0.1</td>\n",
              "      <td>32</td>\n",
              "      <td>{\"false_positive_rate\": [0.0, 0.0, 0.0, 0.0, 0...</td>\n",
              "      <td>{\"epoch\": {\"0\": 0, \"1\": 1, \"2\": 2, \"3\": 3}, \"a...</td>\n",
              "      <td>{\"00\": 800, \"01\": 128, \"10\": 146, \"11\": 781}</td>\n",
              "      <td>4</td>\n",
              "      <td>2.617622</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Bi-LSTM</td>\n",
              "      <td>BASE 0</td>\n",
              "      <td>RMSProp</td>\n",
              "      <td>0.852291</td>\n",
              "      <td>0.327882</td>\n",
              "      <td>0.0001</td>\n",
              "      <td>0.2</td>\n",
              "      <td>32</td>\n",
              "      <td>{\"false_positive_rate\": [0.0, 0.0, 0.0, 0.0, 0...</td>\n",
              "      <td>{\"epoch\": {\"0\": 0, \"1\": 1, \"2\": 2, \"3\": 3}, \"a...</td>\n",
              "      <td>{\"00\": 838, \"01\": 90, \"10\": 184, \"11\": 743}</td>\n",
              "      <td>4</td>\n",
              "      <td>2.599382</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>355</th>\n",
              "      <td>ShallowNet</td>\n",
              "      <td>BASE 2</td>\n",
              "      <td>RMSProp</td>\n",
              "      <td>0.509202</td>\n",
              "      <td>175.864090</td>\n",
              "      <td>0.0001</td>\n",
              "      <td>0.0</td>\n",
              "      <td>64</td>\n",
              "      <td>{\"false_positive_rate\": [0.0, 0.30061349693251...</td>\n",
              "      <td>{\"epoch\": {\"0\": 0, \"1\": 1, \"2\": 2, \"3\": 3, \"4\"...</td>\n",
              "      <td>{\"00\": 323, \"01\": 166, \"10\": 314, \"11\": 175}</td>\n",
              "      <td>5</td>\n",
              "      <td>0.002895</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>356</th>\n",
              "      <td>ShallowNet</td>\n",
              "      <td>BASE 2</td>\n",
              "      <td>SGD</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>82.666985</td>\n",
              "      <td>0.0001</td>\n",
              "      <td>0.0</td>\n",
              "      <td>64</td>\n",
              "      <td>{\"false_positive_rate\": [0.0, 0.0, 0.006134969...</td>\n",
              "      <td>{\"epoch\": {\"0\": 0, \"1\": 1}, \"accuracy\": {\"0\": ...</td>\n",
              "      <td>{\"00\": 486, \"01\": 3, \"10\": 486, \"11\": 3}</td>\n",
              "      <td>2</td>\n",
              "      <td>0.006048</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>357</th>\n",
              "      <td>ShallowNet</td>\n",
              "      <td>BASE 2</td>\n",
              "      <td>Nadam</td>\n",
              "      <td>0.496933</td>\n",
              "      <td>135.945312</td>\n",
              "      <td>0.0010</td>\n",
              "      <td>0.0</td>\n",
              "      <td>64</td>\n",
              "      <td>{\"false_positive_rate\": [0.0, 0.25766871165644...</td>\n",
              "      <td>{\"epoch\": {\"0\": 0, \"1\": 1}, \"accuracy\": {\"0\": ...</td>\n",
              "      <td>{\"00\": 329, \"01\": 160, \"10\": 332, \"11\": 157}</td>\n",
              "      <td>2</td>\n",
              "      <td>0.003655</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>358</th>\n",
              "      <td>ShallowNet</td>\n",
              "      <td>BASE 2</td>\n",
              "      <td>RMSProp</td>\n",
              "      <td>0.516360</td>\n",
              "      <td>121.295631</td>\n",
              "      <td>0.0010</td>\n",
              "      <td>0.0</td>\n",
              "      <td>64</td>\n",
              "      <td>{\"false_positive_rate\": [0.0, 0.31901840490797...</td>\n",
              "      <td>{\"epoch\": {\"0\": 0, \"1\": 1}, \"accuracy\": {\"0\": ...</td>\n",
              "      <td>{\"00\": 290, \"01\": 199, \"10\": 274, \"11\": 215}</td>\n",
              "      <td>2</td>\n",
              "      <td>0.004257</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>359</th>\n",
              "      <td>ShallowNet</td>\n",
              "      <td>BASE 2</td>\n",
              "      <td>SGD</td>\n",
              "      <td>0.536810</td>\n",
              "      <td>4.673399</td>\n",
              "      <td>0.0010</td>\n",
              "      <td>0.0</td>\n",
              "      <td>64</td>\n",
              "      <td>{\"false_positive_rate\": [0.0, 0.02453987730061...</td>\n",
              "      <td>{\"epoch\": {\"0\": 0, \"1\": 1}, \"accuracy\": {\"0\": ...</td>\n",
              "      <td>{\"00\": 263, \"01\": 226, \"10\": 227, \"11\": 262}</td>\n",
              "      <td>2</td>\n",
              "      <td>0.114865</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>360 rows × 13 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9d0f9926-e08f-48b0-9036-736c48b2d2c3')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-9d0f9926-e08f-48b0-9036-736c48b2d2c3 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-9d0f9926-e08f-48b0-9036-736c48b2d2c3');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 137
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D0hk9_ndbmUK"
      },
      "source": [
        "## Lendo a Base"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if BASE_NAME == 'BASE 0':\n",
        "  # PATH_BASE0_NAO_PROCESSADA  -Base0 Bruta Não processada\n",
        "  PATH_BASE = \"/content/drive/MyDrive/TCC/dados/processadas/balanceadas/Base0_classificada_balanceada.csv\"\n",
        "\n",
        "if BASE_NAME == 'BASE 1':\n",
        "  # PATH_BASE1_JUNTO_COM_DA_LEILA_BALANCEADA - Base1 Com StopWords\n",
        "  PATH_BASE = \"/content/drive/MyDrive/TCC/dados/processadas/balanceadas/Base1JuntaHateENotHateDaLeila_balanceada.csv\"\n",
        "\n",
        "if BASE_NAME == 'BASE 2':\n",
        "  # PATH_BASE2_LEILA_LIMPISSIMA_BALANCEADA - Base2 Sem StopWords\n",
        "  PATH_BASE = \"/content/drive/MyDrive/TCC/dados/processadas/balanceadas/Base2_maior4_menor25_limpissima_balanceada.csv\""
      ],
      "metadata": {
        "id": "W6LWWnwVpLVQ"
      },
      "execution_count": 138,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Base0 Bruta Não processada\n",
        "# PATH_BASE_1_CLASSIFICADA_BALANCEADA = r\"/content/drive/MyDrive/TCC/dados/processadas/balanceadas/Base1_classificada_balanceada.csv\"\n",
        "# #Base0 Bruta Não processada\n",
        "# PATH_BASE_2_CLASSIFICADA_BALANCEADA = r\"/content/drive/MyDrive/TCC/dados/processadas/balanceadas/Base2_classificada_balanceada.csv\"\n",
        "# #MATRIZ_CBOW_300_BASE_1 = loadtxt(\"/content/drive/MyDrive/TCC/dados/word_embeddings/Matriz_Base1JuntaHateENotHateDaLeila_balanceada_CBOW300.CSV\", delimiter=',')\n",
        "# #MATRIZ_CBOW_300_BASE_2_LEILA = loadtxt(\"/content/drive/MyDrive/TCC/dados/word_embeddings/Matriz_Base2_maior4_menor25_limpissima_balanceada_CBOW300.CSV\", delimiter=',')\n",
        "# #MATRIZ_CBOW_300_BASE_2 = loadtxt(\"/content/drive/MyDrive/TCC/dados/word_embeddings/Matriz_Base2_classificada_balanceada_CBOW300.csv\", delimiter=',') #saida"
      ],
      "metadata": {
        "id": "XvX04uKCpOKR"
      },
      "execution_count": 139,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tweets = pd.read_csv(PATH_BASE, index_col=0)\n",
        "tweets"
      ],
      "metadata": {
        "id": "7wJXwK7jCkyx",
        "outputId": "4faad037-ba80-4a2b-d002-79fc5587c7d1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        }
      },
      "execution_count": 140,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                   text  label\n",
              "0     RT @ThomasM71708305: @allantercalivre A Bahia ...      1\n",
              "1     @allantercalivre @gen_heleno @CNNBrasil O Gene...      1\n",
              "2     @allantercalivre @gen_heleno @CNNBrasil Alan t...      1\n",
              "3     @allantercalivre @OlavoOpressor @opropriolavo ...      1\n",
              "4     RT @ThomasM71708305: @allantercalivre A Bahia ...      1\n",
              "...                                                 ...    ...\n",
              "9269        simplesmente amoooo https://t.co/I12jVsUdvb      0\n",
              "9270  @Mary_Greicy Abençoado Ano Novo  sua linda e q...      0\n",
              "9271  @MarcusConcolato leva eles com a gente, eles s...      0\n",
              "9272  se tu NUNCA fumou maconha cole isso no seu mur...      0\n",
              "9273         @trizbeiro Kkkkk kkk ata eu sou meia sonsa      0\n",
              "\n",
              "[9274 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-52d2cd0a-3105-46b1-a881-1598d3ca6310\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>RT @ThomasM71708305: @allantercalivre A Bahia ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>@allantercalivre @gen_heleno @CNNBrasil O Gene...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>@allantercalivre @gen_heleno @CNNBrasil Alan t...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>@allantercalivre @OlavoOpressor @opropriolavo ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>RT @ThomasM71708305: @allantercalivre A Bahia ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9269</th>\n",
              "      <td>simplesmente amoooo https://t.co/I12jVsUdvb</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9270</th>\n",
              "      <td>@Mary_Greicy Abençoado Ano Novo  sua linda e q...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9271</th>\n",
              "      <td>@MarcusConcolato leva eles com a gente, eles s...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9272</th>\n",
              "      <td>se tu NUNCA fumou maconha cole isso no seu mur...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9273</th>\n",
              "      <td>@trizbeiro Kkkkk kkk ata eu sou meia sonsa</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>9274 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-52d2cd0a-3105-46b1-a881-1598d3ca6310')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-52d2cd0a-3105-46b1-a881-1598d3ca6310 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-52d2cd0a-3105-46b1-a881-1598d3ca6310');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 140
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Pega a quantidade de palavras únicas dos tweets de toda a base\n",
        "_, text_tokenizer = tokenize(tweets['text'])\n",
        "text_vocab_size = len(text_tokenizer.word_index)\n",
        "print(\"Vocabulary size:\", text_vocab_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Iw6rCZU1pZHh",
        "outputId": "ad5f2094-d0d3-475f-822b-e9f7abb1a17a"
      },
      "execution_count": 141,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocabulary size: 24839\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Prepara os dados de train, test e validation da base\n"
      ],
      "metadata": {
        "id": "Ax2iFKj9iNhG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Base0 NÃO Processada\n",
        "PATH_BASE0_NAO_PROCESSADA = \"/content/drive/MyDrive/TCC/dados/processadas/balanceadas/Base0_classificada_balanceada.csv\"\n",
        "\n",
        "# Base1 Com StopWords\n",
        "PATH_BASE1_JUNTO_COM_DA_LEILA_BALANCEADA = \"/content/drive/MyDrive/TCC/dados/processadas/balanceadas/Base1JuntaHateENotHateDaLeila_balanceada.csv\"\n",
        "\n",
        "# Base2 Sem StopWords\n",
        "PATH_BASE2_LEILA_LIMPISSIMA_BALANCEADA = \"/content/drive/MyDrive/TCC/dados/processadas/balanceadas/Base2_maior4_menor25_limpissima_balanceada.csv\"\n",
        "\n",
        "NUM_BASES = 3"
      ],
      "metadata": {
        "id": "CRRToRiMNEon"
      },
      "execution_count": 142,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Leitura das bases\n",
        "tweets_base0 = pd.read_csv(PATH_BASE0_NAO_PROCESSADA, index_col=0)\n",
        "print(tweets_base0.shape)\n",
        "tweets_base1 = pd.read_csv(PATH_BASE1_JUNTO_COM_DA_LEILA_BALANCEADA, index_col=0)\n",
        "print(tweets_base1.shape)\n",
        "tweets_base2 = pd.read_csv(PATH_BASE2_LEILA_LIMPISSIMA_BALANCEADA, index_col=0)\n",
        "print(tweets_base2.shape)\n",
        "\n",
        "bases = [tweets_base0, tweets_base1, tweets_base2]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RXndLzw6NRkf",
        "outputId": "d54e4a0b-f51c-4562-e714-75e781b46879"
      },
      "execution_count": 143,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(9274, 2)\n",
            "(16036, 2)\n",
            "(4886, 2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Gera as quantidades das divisões de cada base (train 60%, test 20% e validation 20%)\n",
        "list_test_size = []\n",
        "list_train_size = [] # Só para verificação, não é usado posteriormente\n",
        "list_val_size = []\n",
        "input_datas = []\n",
        "output_labels = []\n",
        "for base in bases:\n",
        "  val_size = base.shape[0]/5 # 20%\n",
        "  val_size = int(math.ceil(val_size))\n",
        "\n",
        "  test_size = base.shape[0]/5 # 20%\n",
        "  test_size = int(math.ceil(test_size))\n",
        "\n",
        "  train_size = base.shape[0] - (test_size+val_size)\n",
        "  list_test_size.append(test_size)\n",
        "  list_train_size.append(train_size)\n",
        "  list_val_size.append(val_size)\n",
        "\n",
        "  input_data, _ = base['text'], None\n",
        "  input_datas.append(input_data)\n",
        "  output_labels.append(base['label'])\n",
        "\n",
        "print('list_train_size: '+str(list_train_size))\n",
        "print('list_test_size: '+str(list_test_size))\n",
        "print('list_val_size: '+str(list_val_size))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c6CNnSONWt21",
        "outputId": "50c67f9a-8400-4459-f19f-2749b0f2126b"
      },
      "execution_count": 144,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "list_train_size: [5564, 9620, 2930]\n",
            "list_test_size: [1855, 3208, 978]\n",
            "list_val_size: [1855, 3208, 978]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Divide cada base em 3 fatias (train, test e val). Para cada fatia temos os dados X e as labels Y\n",
        "list_x_train = []\n",
        "list_y_train = []\n",
        "list_x_test = []\n",
        "list_y_test = []\n",
        "list_x_val = []\n",
        "list_y_val = []\n",
        "for i in range(NUM_BASES):\n",
        "  x_main, x_test, y_main, y_test = train_test_split(input_datas[i], output_labels[i], test_size=list_test_size[i], stratify=output_labels[i], random_state=42)\n",
        "\n",
        "  x_train, x_val, y_train, y_val = train_test_split(x_main, y_main, test_size=list_val_size[i], stratify=y_main, random_state=42)\n",
        "\n",
        "  list_x_train.append(x_train)\n",
        "  list_y_train.append(y_train)\n",
        "  list_x_test.append(x_test)\n",
        "  list_y_test.append(y_test)\n",
        "  list_x_val.append(x_val)\n",
        "  list_y_val.append(y_val)\n"
      ],
      "metadata": {
        "id": "UbxE9QtsN_pT"
      },
      "execution_count": 145,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Execução modelo"
      ],
      "metadata": {
        "id": "O4xH2XQ1AGjE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.naive_bayes import MultinomialNB # or any other NB model\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import confusion_matrix"
      ],
      "metadata": {
        "id": "Fg-cJ5lsXzg4"
      },
      "execution_count": 164,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(classifier, input, output, input_test, output_test, input_val, output_val):\n",
        "    # Train\n",
        "    classifier.fit(input, output)\n",
        "   \n",
        "    # Val\n",
        "    predictions = classifier.predict(input_val)\n",
        "    \n",
        "    acc_score = accuracy_score(output_val, predictions)\n",
        "    false_positive_rate, true_positive_rate, _ = roc_curve(output_val, predictions)     \n",
        "\n",
        "    conf_mat = confusion_matrix(output_val, predictions)\n",
        "    fig, ax = plot_confusion_matrix(figsize=(11, 11),\n",
        "                                  conf_mat=conf_mat,\n",
        "                                  colorbar=True,\n",
        "                                  show_absolute=True,\n",
        "                                  show_normed=True,\n",
        "                                )\n",
        "    plt.title('Matriz de Confusão da rede.') \n",
        "    plt.show()\n",
        "\n",
        "    plt.figure(figsize=(8,6), dpi=80)\n",
        "    colors = [\"red\", \"blue\", \"darkorange\", \"aqua\", \"magenta\", \"lime\", \"cornflowerblue\"] \n",
        "    # false_positive_rate, true_positive_rate, score = list(roc_curve[0].keys())\n",
        "    # false_positive_rate = roc_curve[0][false_positive_rate]\n",
        "    # true_positive_rate = roc_curve[0][true_positive_rate]\n",
        "    # score = roc_curve[0][score]\n",
        "    \n",
        "    # if roc_curve[2] == 'Nadam':\n",
        "    #   color = colors[0]\n",
        "    # if roc_curve[2] == 'RMSProp':\n",
        "    #   color = colors[1]  \n",
        "    # if roc_curve[2] == 'SGD':\n",
        "    #   color = colors[2]\n",
        "    \n",
        "    plt.plot(false_positive_rate, true_positive_rate, color=\"red\", label=\"{0}\".format(acc_score))\n",
        "\n",
        "    plt.plot([0, 1], [0, 1], \"k--\")\n",
        "    plt.xlim([0.0, 1.0])\n",
        "    plt.ylim([0.0, 1.0])\n",
        "    plt.xlabel(\"False Positive Rate\")\n",
        "    plt.ylabel(\"True Positive Rate\")\n",
        "    plt.title('Gráfico da curva ROC de todas as redes pesquisadas.')\n",
        "    plt.legend(loc=\"lower right\")\n",
        "    plt.show()\n",
        "    \n",
        "    \n",
        "    # Test\n",
        "    acc = classifier.score(input_test, output_test)  \n",
        "\n",
        "    return acc"
      ],
      "metadata": {
        "id": "Qp_Nnos4BCCr"
      },
      "execution_count": 178,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy = []\n",
        "for i in range(NUM_BASES):\n",
        "  # create a count vectorizer object \n",
        "  count_vect = CountVectorizer(analyzer='word', token_pattern=r'\\w{1,}')\n",
        "  count_vect.fit(bases[i]['text'])\n",
        "\n",
        "  # train_x, valid_x, train_y, valid_y = model_selection.train_test_split(text_column, output_label, test_size=0.3, random_state=42)\n",
        "  encoder = preprocessing.LabelEncoder() # !!!\n",
        "  train_y = encoder.fit_transform(list_y_train[i])\n",
        "  test_y = encoder.fit_transform(list_y_test[i])\n",
        "  val_y = encoder.fit_transform(list_y_val[i])\n",
        "\n",
        "  # transform the training and validation data using count vectorizer object\n",
        "  train_x =  count_vect.transform(list_x_train[i])\n",
        "  test_x =  count_vect.transform(list_x_test[i])\n",
        "  val_x =  count_vect.transform(list_x_val[i])\n",
        "\n",
        "  # Naive Bayes on Count Vectors\n",
        "  acc = train_model(naive_bayes.MultinomialNB(), train_x, train_y, test_x, test_y, val_x, val_y )\n",
        "\n",
        "  # Parâmetros\n",
        "  NOME_REDE = \"MultinomialNB\"\n",
        "  \n",
        "  NOME_BASE = ''\n",
        "  if NUM_BASES ==  0:\n",
        "    NOME_BASE == 'BASE 0'\n",
        "  if NUM_BASES == 1:\n",
        "    NOME_BASE == 'BASE 1'\n",
        "  if NUM_BASES == 2:\n",
        "    NOME_BASE =='BASE 2'\n",
        "\n",
        "  NOME_OTIMIZADOR = ''\n",
        "  ACURACIA = acc\n",
        "  LOSS = scores[0] \n",
        "  LEARNING_RATE = ''\n",
        "  DROPOUT_RATE = ''\n",
        "  BATCH = ''\n",
        "  ROC_CURVE = json.dumps({\n",
        "      \"false_positive_rate\": list(ra_val.false_positive_rate),\n",
        "      \"true_positive_rate\": list(ra_val.true_positive_rate),\n",
        "      \"score\": ra_val.score})\n",
        "  TRAIN_RESUME = json.dumps(pd.read_csv('log.csv',sep=';').to_dict()) \n",
        "\n",
        "  confusion = confusion_matrix(y_gabarito, y_predito)\n",
        "  CONFUSION_MATRIX = json.dumps({\n",
        "      \"00\": int(confusion[0][0]),\n",
        "      \"01\": int(confusion[0][1]),\n",
        "      \"10\": int(confusion[1][0]),\n",
        "      \"11\": int(confusion[1][1])\n",
        "  })\n",
        "\n",
        "  EPOCHS = len(history.history['val_loss'])\n",
        "  RANK = ACURACIA/LOSS\n",
        "\n",
        "  # Salvando resultado do modelo\n",
        "  registro_resultado = {resultados.columns[0]: NOME_REDE, \n",
        "                        resultados.columns[1]: NOME_BASE, \n",
        "                        resultados.columns[2]: NOME_OTIMIZADOR,\n",
        "                        resultados.columns[3]: ACURACIA, \n",
        "                        resultados.columns[4]: LOSS,\n",
        "                        resultados.columns[5]: LEARNING_RATE,\n",
        "                        resultados.columns[6]: DROPOUT_RATE,\n",
        "                        resultados.columns[7]: BATCH,\n",
        "                        resultados.columns[8]: ROC_CURVE,\n",
        "                        resultados.columns[9]: TRAIN_RESUME,\n",
        "                        resultados.columns[10]: CONFUSION_MATRIX,\n",
        "                        resultados.columns[11]: EPOCHS,\n",
        "                        resultados.columns[12]: RANK,\n",
        "                      }\n",
        "\n",
        "  resultados = resultados.append(registro_resultado, ignore_index=True)"
      ],
      "metadata": {
        "id": "cudOf7vJAGK9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "resultados.head()"
      ],
      "metadata": {
        "id": "IyYXjusOASJm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "resultados.tail(36)"
      ],
      "metadata": {
        "id": "mUbhxhFeVe2J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Caso queira deletar uma linha use o código abaixo\n",
        "# Use a propriedade label para especificar o índice da linha\n",
        "#resultados = resultados.drop(labels=1, axis=0)\n",
        "#resultados = resultados.reset_index(drop=True)\n",
        "#resultados"
      ],
      "metadata": {
        "id": "nP3enYmss2v9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Salva arquivo de saída\n",
        "resultados.to_csv(PATH_ARQ_SAIDA)"
      ],
      "metadata": {
        "id": "y519ohA8u9jW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # word level tf-idf\n",
        "# tfidf_vect = TfidfVectorizer(analyzer='word', token_pattern=r'\\w{1,}', max_features = max_text_length)\n",
        "# X = tfidf_vect.fit_transform(text_column)\n",
        "\n",
        "# train_x, valid_x, train_y, valid_y = model_selection.train_test_split(X, output_label, test_size=0.3, random_state=42)\n",
        "\n",
        "# # Naive Bayes on Word Level TF IDF Vectors\n",
        "# accuracy.append(train_model(naive_bayes.MultinomialNB(), train_x, train_y, valid_x))\n",
        "# print (\"NB, WordLevel TF-IDF: \", accuracy)"
      ],
      "metadata": {
        "id": "Dx7c4MlFoBaH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # ngram level tf-idf\n",
        "# tfidf_vect_ngram = TfidfVectorizer(analyzer='word', token_pattern=r'\\w{1,}', ngram_range=(1,2), max_features=max_text_length)\n",
        "# X = tfidf_vect_ngram.fit_transform(text_column)\n",
        "\n",
        "# train_x, valid_x, train_y, valid_y = model_selection.train_test_split(X, output_label, test_size=0.3, random_state=42)\n",
        "\n",
        "# # Naive Bayes on Ngram Level TF IDF Vectors\n",
        "# accuracy.append(train_model(naive_bayes.MultinomialNB(), train_x, train_y, valid_x))\n",
        "# print (\"NB, N-Gram(1,2) Vectors: \", accuracy)"
      ],
      "metadata": {
        "id": "3TKYt7dbs5m4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # ngram level tf-idf\n",
        "# tfidf_vect_ngram = TfidfVectorizer(analyzer='word', token_pattern=r'\\w{1,}', ngram_range=(2,3), max_features=max_text_length)\n",
        "# X = tfidf_vect_ngram.fit_transform(text_column)\n",
        "\n",
        "# train_x, valid_x, train_y, valid_y = model_selection.train_test_split(X, output_label, test_size=0.3, random_state=42)\n",
        "\n",
        "# # Naive Bayes on Ngram Level TF IDF Vectors\n",
        "# accuracy.append(train_model(naive_bayes.MultinomialNB(), train_x, train_y, valid_x))\n",
        "# print (\"NB, N-Gram(2,3) Vectors: \", accuracy)"
      ],
      "metadata": {
        "id": "dlQXeIcboCKh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # characters level tf-idf\n",
        "# tfidf_vect_ngram_chars = TfidfVectorizer(analyzer='char', token_pattern=r'\\w{1,}', ngram_range=(2,3), max_features=max_text_length)\n",
        "# X = tfidf_vect_ngram_chars.fit_transform(text_column) \n",
        "\n",
        "# train_x, valid_x, train_y, valid_y = model_selection.train_test_split(X, output_label, test_size=0.3, random_state=42)\n",
        "\n",
        "# # Naive Bayes on Character Level TF IDF Vectors\n",
        "# accuracy.append(train_model(naive_bayes.MultinomialNB(), train_x, train_y, valid_x))\n",
        "# print (\"NB, N-Gram(2,3) CharLevel Vectors: \", accuracy)"
      ],
      "metadata": {
        "id": "7qKpWlUWoEWf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # characters level tf-idf\n",
        "# tfidf_vect_ngram_chars = TfidfVectorizer(analyzer='char', token_pattern=r'\\w{1,}', ngram_range=(1,120), max_features=max_text_length)\n",
        "# X = tfidf_vect_ngram_chars.fit_transform(text_column) \n",
        "\n",
        "# train_x, valid_x, train_y, valid_y = model_selection.train_test_split(X, output_label, test_size=0.3, random_state=2)\n",
        "\n",
        "# # Naive Bayes on Character Level TF IDF Vectors\n",
        "# accuracy.append(train_model(naive_bayes.MultinomialNB(), train_x, train_y, valid_x))\n",
        "# print (\"NB, N-Gram(2,3) CharLevel Vectors: \", accuracy)"
      ],
      "metadata": {
        "id": "PSIecyy4gD1I"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}