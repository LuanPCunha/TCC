{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled2.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPdR12BbNKzX30xdnY8C8MC",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LuanPCunha/TCC/blob/main/TunningCNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hl5ZHhSo4MKX"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Downloads e imports"
      ],
      "metadata": {
        "id": "EvS_6l_yMUeH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install tensorflow\n",
        "# !pip install keras\n",
        "# !pip install keras-tuner"
      ],
      "metadata": {
        "id": "N5Vhr4_vECld",
        "outputId": "f1048cba-2ecd-4249-90b7-e97d3e83a7be",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.7/dist-packages (2.8.2+zzzcolab20220527125636)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.1.0)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.21.6)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from tensorflow) (57.4.0)\n",
            "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.17.3)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.15.0)\n",
            "Requirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (14.0.1)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.14.1)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.1.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.26.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.46.3)\n",
            "Requirement already satisfied: gast>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.5.3)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.1.2)\n",
            "Requirement already satisfied: flatbuffers>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.9,>=2.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.8.0)\n",
            "Requirement already satisfied: tensorboard<2.9,>=2.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.8.0)\n",
            "Requirement already satisfied: keras<2.9,>=2.8.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.8.0)\n",
            "Requirement already satisfied: absl-py>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.1.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (4.1.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from astunparse>=1.6.0->tensorflow) (0.37.1)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow) (1.5.2)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (1.35.0)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (2.23.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (0.6.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (0.4.6)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (1.8.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (3.3.7)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (1.0.1)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (4.2.4)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (4.8)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow) (4.11.4)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow) (3.8.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (0.4.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (2022.6.15)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (1.24.3)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow) (3.2.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.7/dist-packages (2.8.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: keras-tuner in /usr/local/lib/python3.7/dist-packages (1.1.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from keras-tuner) (2.23.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from keras-tuner) (1.21.6)\n",
            "Requirement already satisfied: kt-legacy in /usr/local/lib/python3.7/dist-packages (from keras-tuner) (1.0.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from keras-tuner) (21.3)\n",
            "Requirement already satisfied: ipython in /usr/local/lib/python3.7/dist-packages (from keras-tuner) (5.5.0)\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.7/dist-packages (from keras-tuner) (2.8.0)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner) (0.7.5)\n",
            "Requirement already satisfied: pexpect in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner) (4.8.0)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner) (57.4.0)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner) (5.1.1)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner) (2.6.1)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner) (1.0.18)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner) (4.4.2)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner) (0.8.1)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython->keras-tuner) (0.2.5)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython->keras-tuner) (1.15.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->keras-tuner) (3.0.9)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.7/dist-packages (from pexpect->ipython->keras-tuner) (0.7.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->keras-tuner) (2022.6.15)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->keras-tuner) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->keras-tuner) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->keras-tuner) (1.24.3)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (1.1.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (1.8.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (1.0.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (0.6.1)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (1.46.3)\n",
            "Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (3.17.3)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (0.37.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (3.3.7)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (1.35.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (0.4.6)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard->keras-tuner) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard->keras-tuner) (4.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard->keras-tuner) (4.2.4)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard->keras-tuner) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard->keras-tuner) (4.11.4)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard->keras-tuner) (4.1.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard->keras-tuner) (3.8.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard->keras-tuner) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard->keras-tuner) (3.2.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ptoQwAGEDQnl",
        "outputId": "5b5d449b-1a70-4f8d-ee34-7e004100af44"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import sklearn\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from numpy import loadtxt\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras import optimizers\n",
        "from keras import layers\n",
        "from keras.layers import Dropout, Conv1D, MaxPooling1D, Flatten, Dense, SpatialDropout1D, BatchNormalization\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.optimizers import schedules, Adam, Adadelta, SGD, RMSprop, Adagrad, Adamax, Nadam, Ftrl # Estamos usando só o Nadam\n",
        "from keras.models import Sequential\n",
        "from keras.layers.embeddings import Embedding\n",
        "\n",
        "from mlxtend.plotting import plot_confusion_matrix\n",
        "from keras.callbacks import Callback, ModelCheckpoint, CSVLogger\n",
        "from sklearn.metrics import roc_auc_score, roc_curve, confusion_matrix\n",
        "\n",
        "import keras_tuner"
      ],
      "metadata": {
        "id": "OeOYrHW9Bxs_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize(tweets_list):\n",
        "    tokenizer = Tokenizer()\n",
        "    tokenizer.fit_on_texts(tweets_list)\n",
        "    return tokenizer.texts_to_sequences(tweets_list), tokenizer"
      ],
      "metadata": {
        "id": "db4KNc_2Ixyu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def pad(text_tokenized, length=None):\n",
        "    return pad_sequences(text_tokenized, maxlen=length, padding='post')"
      ],
      "metadata": {
        "id": "pwcjgZd9I6AD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess(tweets_list, max_text_length):\n",
        "   \n",
        "    preprocess_tweets_list, tweets_list_tokenizer = tokenize(tweets_list)\n",
        "\n",
        "    preprocess_tweets_list = pad(preprocess_tweets_list, length=max_text_length)\n",
        "\n",
        "    return preprocess_tweets_list, tweets_list_tokenizer"
      ],
      "metadata": {
        "id": "fNMyJgcsI8AU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def logits_to_text(logits, tokenizer):\n",
        "    index_to_words = {id: word for word, id in tokenizer.word_index.items()}\n",
        "    index_to_words[0] = '<PAD>'\n",
        "\n",
        "    return ' '.join([index_to_words[prediction] for prediction in np.argmax(logits, 1)])"
      ],
      "metadata": {
        "id": "pX78imOBI9l8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class RocAucEvaluation(Callback):\n",
        "    def __init__(self, validation_data=(), interval=1):\n",
        "        super(Callback, self).__init__()\n",
        "\n",
        "        self.interval = interval\n",
        "        self.X_val, self.y_val = validation_data\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs={}):\n",
        "        if epoch % self.interval == 0:\n",
        "            y_pred = self.model.predict(self.X_val, verbose=0)\n",
        "            self.score = roc_auc_score(self.y_val, y_pred)\n",
        "            self.false_positive_rate, self.true_positive_rate, _ = roc_curve(self.y_val, y_pred)\n",
        "            print(\"\\n ROC-AUC - epoch: {:d} - score: {:.6f}\".format(epoch+1, self.score))             "
      ],
      "metadata": {
        "id": "DLBaKxGhrbRU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Carrega arquivo de saída (resultados)"
      ],
      "metadata": {
        "id": "rbA3XJK6kIrM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# CONSTANTES DOS RESULTADOS\n",
        "\n",
        "REDE_CNN = 'CNN'\n",
        "REDE_LSTM = 'LSTM'\n",
        "REDE_BILSTM = 'Bi-LSTM'\n",
        "\n",
        "BASE_1 = 'BASE 1'\n",
        "BASE_2 = 'BASE 2'\n",
        "\n",
        "FUNCAO_ATV_SIGMOID = 'SIGMOID'\n",
        "FUNCAO_ATV_SOFTMAX = 'SOFTMAX'\n",
        "FUNCAO_ATV_RELU = 'RELU'\n",
        "\n",
        "OTIMIZADOR_1 = '1'\n",
        "OTIMIZADOR_2 = '2'\n",
        "OTIMIZADOR_3 = '3'\n",
        "OTIMIZADOR_4 = '4'\n",
        "\n",
        "# Caminho arquivo de saída\n",
        "PATH_ARQ_SAIDA = \"/content/drive/MyDrive/TCC/resultados/resultados.csv\"\n",
        "\n",
        "resultados = pd.read_csv(PATH_ARQ_SAIDA, index_col=0)\n",
        "resultados.head()"
      ],
      "metadata": {
        "id": "wvPJKDAQnAUQ",
        "outputId": "e77bae2b-a336-449a-a528-2107716932a8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "  rede    base funcao_ativacao  otimizador  acuracia  \\\n",
              "0  CNN  BASE 2         SIGMOID           1  0.919622   \n",
              "1  CNN  BASE 2         SIGMOID           1  0.925768   \n",
              "2  CNN  BASE 2         SIGMOID           1  0.928605   \n",
              "3  CNN  BASE 2         SIGMOID           1  0.921513   \n",
              "4  CNN  BASE 2         SIGMOID           1  0.927187   \n",
              "\n",
              "                                           roc_curve  \\\n",
              "0  {\"false_positive_rate\": [0.0, 0.0, 0.0, 0.0, 0...   \n",
              "1  {\"false_positive_rate\": [0.0, 0.0, 0.0, 0.0, 0...   \n",
              "2  {\"false_positive_rate\": [0.0, 0.0, 0.0, 0.0, 0...   \n",
              "3  {\"false_positive_rate\": [0.0, 0.0, 0.0, 0.0, 0...   \n",
              "4  {\"false_positive_rate\": [0.0, 0.0, 0.0, 0.0, 0...   \n",
              "\n",
              "                                        train_resume  \\\n",
              "0  {\"epoch\": {\"0\": 0, \"1\": 1, \"2\": 2, \"3\": 3, \"4\"...   \n",
              "1  {\"epoch\": {\"0\": 0, \"1\": 1, \"2\": 2, \"3\": 3, \"4\"...   \n",
              "2  {\"epoch\": {\"0\": 0, \"1\": 1, \"2\": 2, \"3\": 3, \"4\"...   \n",
              "3  {\"epoch\": {\"0\": 0, \"1\": 1, \"2\": 2, \"3\": 3, \"4\"...   \n",
              "4  {\"epoch\": {\"0\": 0, \"1\": 1, \"2\": 2, \"3\": 3, \"4\"...   \n",
              "\n",
              "                             confusion_matrix  \n",
              "0  {\"00\": 954, \"01\": 93, \"10\": 77, \"11\": 991}  \n",
              "1  {\"00\": 983, \"01\": 64, \"10\": 93, \"11\": 975}  \n",
              "2  {\"00\": 970, \"01\": 77, \"10\": 74, \"11\": 994}  \n",
              "3  {\"00\": 952, \"01\": 95, \"10\": 71, \"11\": 997}  \n",
              "4  {\"00\": 974, \"01\": 73, \"10\": 81, \"11\": 987}  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7703ed3a-50a2-444e-b75a-a25fe949c21a\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>rede</th>\n",
              "      <th>base</th>\n",
              "      <th>funcao_ativacao</th>\n",
              "      <th>otimizador</th>\n",
              "      <th>acuracia</th>\n",
              "      <th>roc_curve</th>\n",
              "      <th>train_resume</th>\n",
              "      <th>confusion_matrix</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>CNN</td>\n",
              "      <td>BASE 2</td>\n",
              "      <td>SIGMOID</td>\n",
              "      <td>1</td>\n",
              "      <td>0.919622</td>\n",
              "      <td>{\"false_positive_rate\": [0.0, 0.0, 0.0, 0.0, 0...</td>\n",
              "      <td>{\"epoch\": {\"0\": 0, \"1\": 1, \"2\": 2, \"3\": 3, \"4\"...</td>\n",
              "      <td>{\"00\": 954, \"01\": 93, \"10\": 77, \"11\": 991}</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>CNN</td>\n",
              "      <td>BASE 2</td>\n",
              "      <td>SIGMOID</td>\n",
              "      <td>1</td>\n",
              "      <td>0.925768</td>\n",
              "      <td>{\"false_positive_rate\": [0.0, 0.0, 0.0, 0.0, 0...</td>\n",
              "      <td>{\"epoch\": {\"0\": 0, \"1\": 1, \"2\": 2, \"3\": 3, \"4\"...</td>\n",
              "      <td>{\"00\": 983, \"01\": 64, \"10\": 93, \"11\": 975}</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>CNN</td>\n",
              "      <td>BASE 2</td>\n",
              "      <td>SIGMOID</td>\n",
              "      <td>1</td>\n",
              "      <td>0.928605</td>\n",
              "      <td>{\"false_positive_rate\": [0.0, 0.0, 0.0, 0.0, 0...</td>\n",
              "      <td>{\"epoch\": {\"0\": 0, \"1\": 1, \"2\": 2, \"3\": 3, \"4\"...</td>\n",
              "      <td>{\"00\": 970, \"01\": 77, \"10\": 74, \"11\": 994}</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>CNN</td>\n",
              "      <td>BASE 2</td>\n",
              "      <td>SIGMOID</td>\n",
              "      <td>1</td>\n",
              "      <td>0.921513</td>\n",
              "      <td>{\"false_positive_rate\": [0.0, 0.0, 0.0, 0.0, 0...</td>\n",
              "      <td>{\"epoch\": {\"0\": 0, \"1\": 1, \"2\": 2, \"3\": 3, \"4\"...</td>\n",
              "      <td>{\"00\": 952, \"01\": 95, \"10\": 71, \"11\": 997}</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>CNN</td>\n",
              "      <td>BASE 2</td>\n",
              "      <td>SIGMOID</td>\n",
              "      <td>1</td>\n",
              "      <td>0.927187</td>\n",
              "      <td>{\"false_positive_rate\": [0.0, 0.0, 0.0, 0.0, 0...</td>\n",
              "      <td>{\"epoch\": {\"0\": 0, \"1\": 1, \"2\": 2, \"3\": 3, \"4\"...</td>\n",
              "      <td>{\"00\": 974, \"01\": 73, \"10\": 81, \"11\": 987}</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7703ed3a-50a2-444e-b75a-a25fe949c21a')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-7703ed3a-50a2-444e-b75a-a25fe949c21a button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-7703ed3a-50a2-444e-b75a-a25fe949c21a');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Carrega base"
      ],
      "metadata": {
        "id": "kMO-knebMcYH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Base1 Com StopWords\n",
        "PATH_BASE1_JUNTO_COM_DA_LEILA_BALANCEADA = \"/content/drive/MyDrive/TCC/dados/processadas/balanceadas/Base1JuntaHateENotHateDaLeila_balanceada.csv\"\n",
        "#MATRIZ_CBOW_300_BASE_1 = loadtxt(\"/content/drive/MyDrive/TCC/dados/word_embeddings/Matriz_Base1JuntaHateENotHateDaLeila_balanceada_CBOW300.CSV\", delimiter=',')\n",
        "\n",
        "# Base2 Sem StopWords\n",
        "PATH_BASE2_LEILA_LIMPISSIMA_BALANCEADA = \"/content/drive/MyDrive/TCC/dados/processadas/balanceadas/Base2_maior4_menor25_limpissima_balanceada.csv\"\n",
        "#MATRIZ_CBOW_300_BASE_2_LEILA = loadtxt(\"/content/drive/MyDrive/TCC/dados/word_embeddings/Matriz_Base2_maior4_menor25_limpissima_balanceada_CBOW300.CSV\", delimiter=',')\n",
        "\n",
        "PATH_BASE_1_CLASSIFICADA_BALANCEADA = r\"/content/drive/MyDrive/TCC/dados/processadas/balanceadas/Base1_classificada_balanceada.csv\" #entrada\n",
        "\n",
        "PATH_BASE_2_CLASSIFICADA_BALANCEADA = r\"/content/drive/MyDrive/TCC/dados/processadas/balanceadas/Base2_classificada_balanceada.csv\" #entrada\n",
        "MATRIZ_CBOW_300_BASE_2 = loadtxt(\"/content/drive/MyDrive/TCC/dados/word_embeddings/Matriz_Base2_classificada_balanceada_CBOW300.csv\", delimiter=',') #saida"
      ],
      "metadata": {
        "id": "xf_v4U5DDfU8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Execução modelo"
      ],
      "metadata": {
        "id": "W9pdFxE7Ml6H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tweets = pd.read_csv(PATH_BASE_2_CLASSIFICADA_BALANCEADA, index_col=0)\n",
        "text_column = tweets['text']\n",
        "text_column"
      ],
      "metadata": {
        "id": "7wJXwK7jCkyx",
        "outputId": "f888edbd-f016-455a-c8d2-730e87b4f1c8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0        retwet bahia fazer sendo governada pt sei baia...\n",
              "1        k imagine atitude mental negativa f idiota fec...\n",
              "2        general heleno é bolsonaro rosna late late lat...\n",
              "3        alan ser cara pau achar havendo ruptura nesse ...\n",
              "4        canalhascomunistas caçarão chapa presidencialn...\n",
              "                               ...                        \n",
              "10569               af hein amiga mandar outro número mail\n",
              "10570    egoísmo é grande parte produto sociedade émile...\n",
              "10571    abençoado novo linda querida obrigada carinho ...\n",
              "10572                              leva gente amorzinhos d\n",
              "10573                                   k k ata meia sonsa\n",
              "Name: text, Length: 10574, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Pega a média de caracteres dos tweets de toda a base\n",
        "max_text_length = int(text_column.apply(lambda x: len(str(x).split(' '))).max())\n",
        "max_text_length"
      ],
      "metadata": {
        "id": "ud3ADezRSHtI",
        "outputId": "76b0bada-7479-44e1-af63-9e459f43923b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "55"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UxNdO2PW2E5a",
        "outputId": "dcca3493-e0f9-4d35-ca6c-d51019366e18"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocabulary size: 19043\n"
          ]
        }
      ],
      "source": [
        "output_label = tweets['label']\n",
        "input_data, text_tokenizer = preprocess(text_column, None)\n",
        "    \n",
        "text_vocab_size = len(text_tokenizer.word_index)\n",
        "print(\"Vocabulary size:\", text_vocab_size)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# * Otmizadores : 1 de cada 'família'   (Nadam, RMSProp, SGD, Ftrl)\n",
        "# * Bactch size :  32 e 64\n",
        "# * val e test size : .2 e .33 \n",
        "# * learning rate : '0.0001' e '0.001' e '0.00001'\n",
        "# * Dropout Rate: 0, 0.1, 0.2\n",
        "# * Numero de camadas convolucionais 1 e 2\n",
        "# * Numero de filtros em cada camada 10 , 32 , 64"
      ],
      "metadata": {
        "id": "PlHfwFNOjA2e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# parametros:\n",
        "BATCH_SIZE = 64\n",
        "EPOCHS = 10\n",
        "VAL_AND_TST_SIZE = 0.2\n",
        "# LEARN_RATE = 0.0001\n",
        "# ******\n",
        "# BETA_1 = 0.09\n",
        "# BETA_2 = 0.0999\n",
        "# EPSILON = 1e-07\n",
        "# *****\n",
        "EMBEDDING_DIMENSION = 300  \n",
        "MAX_TEXT_SIZE = max_text_length \n",
        "VOCAB_SIZE = text_vocab_size"
      ],
      "metadata": {
        "id": "yBGbbGdfL7ps"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def search_optimize (hp):\n",
        "\n",
        "  hp_optimizer = hp.Choice('Optimizer', values=['Nadam', 'RMSprop', 'SGD', 'Ftrl'])\n",
        "\n",
        "  if hp_optimizer == 'Nadam':\n",
        "    hp_learning_rate = hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])\n",
        "    # beta_1 = hp.Choice('beta1', values=[9e-1, 99e-2])\n",
        "    # beta_2 = hp.Choice('beta2', values=[999e-3, 9999e-4])\n",
        "    # epsilon = hp.Choice('epsilon', values=[1e-07, 1e-08])\n",
        "  elif hp_optimizer == 'RMSprop':\n",
        "    hp_learning_rate = hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])\n",
        "    # nesterov = hp.Choice('nesterov', values=[True, False])\n",
        "    # rho = hp.Choice('rho', values=[9e-1, 99e-2])\n",
        "    # momentum = hp.Choice('momentum', values=[0.0, 1e-4])\n",
        "    # epsilon = hp.Choice('epsilon', values=[1e-07, 1e-08])\n",
        "    # centered = hp.Choice('nesterov', values=[True, False])\n",
        "  elif hp_optimizer == 'SGD':\n",
        "    hp_learning_rate = hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])\n",
        "    # momentum = hp.Choice('momentum', values=[0.0, 1e-4])\n",
        "    # nesterov = hp.Choice('nesterov', values=[True, False])\n",
        "  elif hp_optimizer == 'Ftrl':\n",
        "    hp_learning_rate = hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])\n",
        "    # learning_rate_power = hp.Choice('learning_rate', values=[-0.5 , -0.2])\n",
        "    # initial_accumulator_value = hp.Choice('learning_rate', values=[0.1, 0.01])\n",
        "    # l1_regularization_strength = hp.Choice('learning_rate', values=[0.1, 0.01])\n",
        "    # l2_regularization_strength = hp.Choice('learning_rate', values=[0.1, 0.01])\n",
        "    # l2_shrinkage_regularization_strength = hp.Choice('learning_rate', values=[0.01, 0.001, 0.001])\n",
        "    # beta = hp.Choice('learning_rate', values=[0.0001, 0.001])\n",
        "  \n",
        " \n",
        "  \n",
        "  return hp_optimizer\n",
        "\n",
        "def search_create_cnn (hp, vocab_size, embedding_dimen, max_text_size ):\n",
        "\n",
        "  modelo = Sequential()\n",
        "\n",
        "  # modelo.add(keras.layers.Embedding(VOCAB_SIZE, EMBEDDING_DIMENSION, input_length=max_text_size))      \n",
        "  # modelo.add(keras.layers.Input(shape=(8459, 55)))\n",
        "  \n",
        "  for i in range(hp.Int('Numero_de_Conv1d', min_value=1, max_value=3)):\n",
        "    hp_padding=hp.Choice('padding_'+ str(i), values=['valid', 'same'])\n",
        "    hp_filters=hp.Choice('filters_'+ str(i), values=[10, 32, 64])\n",
        "    modelo.add(keras.layers.Conv1D(hp_filters,3, padding=hp_padding, activation=\"relu\"))\n",
        "  \n",
        "  modelo.add(keras.layers.Flatten(input_shape=(max_text_size,)))\n",
        "  \n",
        "  for i in range(hp.Int('Numero_de_Camadas_densas',  min_value=1, max_value=3)):\n",
        "    modelo.add(Dense(units=hp.Int('dense_' + str(i), min_value=MAX_TEXT_SIZE, max_value=(MAX_TEXT_SIZE*3), step=MAX_TEXT_SIZE), activation='relu'))\n",
        "    modelo.add(Dropout(hp.Choice('dropout_'+ str(i), values=[0.0, 0.1, 0.2, 0.3])))            \n",
        "                \n",
        "  modelo.add(keras.layers.Dense(1, activation='sigmoid'))\n",
        "  \n",
        " \n",
        "  \n",
        "  return modelo\n",
        "\n",
        "def search_train_model(input_data, output_label, embedding_dimen, batch_size, epochs, validation_and_test_size):\n",
        "   \n",
        "    hp = keras_tuner.HyperParameters()\n",
        "\n",
        "    x_train, x_test, y_train, y_test = train_test_split(input_data, output_label, test_size=validation_and_test_size, random_state=42)\n",
        "\n",
        "    optimizer = search_optimize(hp)\n",
        "    \n",
        "    model = search_create_cnn(hp, VOCAB_SIZE, EMBEDDING_DIMENSION, MAX_TEXT_SIZE)\n",
        "   \n",
        "    model.compile(loss=tf.keras.losses.BinaryCrossentropy(), optimizer=optimizer, metrics=['accuracy'])        \n",
        "    \n",
        "    ra_val = RocAucEvaluation(validation_data=(x_test, y_test), interval = 1)\n",
        "    \n",
        "    csv_logger = CSVLogger('log.csv', append=False, separator=';')                                                                                       \n",
        "    \n",
        "    print(x_train.shape)\n",
        "\n",
        "    print(\"TO AQUI 0\")\n",
        "    tuner_mlp = keras_tuner.tuners.BayesianOptimization(model, seed=42, objective='val_loss', max_trials=30, directory='.', project_name='tuning-cnn')\n",
        "    print(\"TO AQUI 1\")\n",
        "    \n",
        "    hp_batch_size=hp.Choice('batch_size_', values=[32, 64])\n",
        "   \n",
        "    print(\"Estou no Search\")\n",
        "    tuner_mlp.search(x_train, y_train, batch_size=hp_batch_size, epochs=EPOCHS, validation_split = validation_and_test_size, verbose=2, use_multiprocessing=True,  callbacks = [ra_val, csv_logger])"
      ],
      "metadata": {
        "id": "bPL3sYgZ1h7j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "search_train_model(input_data, output_label, EMBEDDING_DIMENSION, BATCH_SIZE, EPOCHS, VAL_AND_TST_SIZE)"
      ],
      "metadata": {
        "id": "yu546gRcjt2N",
        "outputId": "6900e7b1-ae8a-4bc2-ac7d-0cb36022ad7b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 525
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(8459, 55)\n",
            "TO AQUI 0\n",
            "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor. Received: inputs=<keras_tuner.engine.hyperparameters.HyperParameters object at 0x7f3904140310>. Consider rewriting this model with the Functional API.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-50-8172239856ce>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msearch_train_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_label\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEMBEDDING_DIMENSION\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEPOCHS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mVAL_AND_TST_SIZE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-49-fc3ca84ef4d7>\u001b[0m in \u001b[0;36msearch_train_model\u001b[0;34m(input_data, output_label, embedding_dimen, batch_size, epochs, validation_and_test_size)\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"TO AQUI 0\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m     \u001b[0mtuner_mlp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkeras_tuner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtuners\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBayesianOptimization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobjective\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'val_loss'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_trials\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdirectory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'.'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproject_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'tuning-cnn'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"TO AQUI 1\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras_tuner/tuners/bayesian.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, hypermodel, objective, max_trials, num_initial_points, alpha, beta, seed, hyperparameters, tune_new_entries, allow_new_entries, **kwargs)\u001b[0m\n\u001b[1;32m    461\u001b[0m             \u001b[0mBayesianOptimization\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    462\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 463\u001b[0;31m         ).__init__(oracle=oracle, hypermodel=hypermodel, **kwargs)\n\u001b[0m\u001b[1;32m    464\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mscipy\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    465\u001b[0m             raise ImportError(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras_tuner/engine/tuner.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, oracle, hypermodel, max_model_size, optimizer, loss, metrics, distribution_strategy, directory, project_name, logger, tuner_id, overwrite, executions_per_trial)\u001b[0m\n\u001b[1;32m    114\u001b[0m             \u001b[0mproject_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mproject_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogger\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m             \u001b[0moverwrite\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverwrite\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m         )\n\u001b[1;32m    118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras_tuner/engine/base_tuner.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, oracle, hypermodel, directory, project_name, logger, overwrite)\u001b[0m\n\u001b[1;32m    101\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_display\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuner_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDisplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moracle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moracle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_populate_initial_space\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0moverwrite\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tuner_fname\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras_tuner/engine/base_tuner.py\u001b[0m in \u001b[0;36m_populate_initial_space\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhypermodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m             \u001b[0;31m# Update the recored scopes.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/input_spec.py\u001b[0m in \u001b[0;36massert_input_compatibility\u001b[0;34m(input_spec, inputs, layer_name)\u001b[0m\n\u001b[1;32m    195\u001b[0m     \u001b[0;31m# have a `shape` attribute.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'shape'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 197\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Inputs to a layer should be tensors. Got: {x}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_spec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: Exception encountered when calling layer \"sequential_15\" (type Sequential).\n\nInputs to a layer should be tensors. Got: <keras_tuner.engine.hyperparameters.HyperParameters object at 0x7f3904140310>\n\nCall arguments received:\n  • inputs=<keras_tuner.engine.hyperparameters.HyperParameters object at 0x7f3904140310>\n  • training=False\n  • mask=None"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def optimize (hp):\n",
        "\n",
        "  hp_optimizer = hp.Choice('Optimizer', values=['Nadam', 'RMSprop', 'SGD', 'Ftrl'])\n",
        "\n",
        "  if hp_optimizer == 'Nadam':\n",
        "    hp_learning_rate = hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])\n",
        "    beta_1 = hp.Choice('beta1', values=[9e-1, 99e-2])\n",
        "    beta_2 = hp.Choice('beta2', values=[999e-3, 9999e-4])\n",
        "    epsilon = hp.Choice('epsilon', values=[1e-07, 1e-08])\n",
        "  elif hp_optimizer == 'RMSprop':\n",
        "    hp_learning_rate = hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])\n",
        "    nesterov = hp.Choice('nesterov', values=[True, False])\n",
        "    rho = hp.Choice('rho', values=[9e-1, 99e-2])\n",
        "    momentum = hp.Choice('momentum', values=[0.0, 1e-4])\n",
        "    epsilon = hp.Choice('epsilon', values=[1e-07, 1e-08])\n",
        "    centered = hp.Choice('nesterov', values=[True, False])\n",
        "  elif hp_optimizer == 'SGD':\n",
        "    hp_learning_rate = hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])\n",
        "    momentum = hp.Choice('momentum', values=[0.0, 1e-4])\n",
        "    nesterov = hp.Choice('nesterov', values=[True, False])\n",
        "  elif hp_optimizer == 'Ftrl':\n",
        "    hp_learning_rate = hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])\n",
        "    learning_rate_power = hp.Choice('learning_rate', values=[-0.5 , -0.2])\n",
        "    initial_accumulator_value = hp.Choice('learning_rate', values=[0.1, 0.01])\n",
        "    l1_regularization_strength = hp.Choice('learning_rate', values=[0.1, 0.01])\n",
        "    l2_regularization_strength = hp.Choice('learning_rate', values=[0.1, 0.01])\n",
        "    l2_shrinkage_regularization_strength = hp.Choice('learning_rate', values=[0.01, 0.001, 0.001])\n",
        "    beta = hp.Choice('learning_rate', values=[0.0001, 0.001])\n",
        "  \n",
        "  return hp_optimizer\n",
        "\n",
        "def create_cnn (hp, vocab_size, embedding_dimen, max_text_size ):\n",
        "\n",
        "  modelo = Sequential()\n",
        "\n",
        "  \n",
        "\n",
        "  modelo.add(keras.layers.Embedding(VOCAB_SIZE, EMBEDDING_DIMENSION, input_length=max_text_size))      \n",
        "  \n",
        "  for i in range(hp.Int('Numero_de_Conv1d', min_value=1, max_value=3)):\n",
        "    hp_padding=hp.Choice('padding_'+ str(i), values=['valid', 'same'])\n",
        "    hp_filters=hp.Choice('filters_'+ str(i), values=[10, 32, 64])\n",
        "    modelo.add(keras.layers.Conv1D(hp_filters,(3, 3), padding=hp_padding, activation=\"relu\"))\n",
        "  \n",
        "  modelo.add(keras.layers.Flatten(input_shape=(max_text_size,)))\n",
        "  \n",
        "  for i in range(hp.Int('Numero_de_Camadas_densas',  min_value=1, max_value=3)):\n",
        "    modelo.add(Dense(units=hp.Int('dense_' + str(i), min_value=MAX_TEXT_SIZE, max_value=(MAX_TEXT_SIZE*3), step=MAX_TEXT_SIZE), activation='relu'))\n",
        "    modelo.add(Dropout(hp.Choice('dropout_'+ str(i), values=[0.0, 0.1, 0.2, 0.3])))            \n",
        "                \n",
        "  modelo.add(keras.layers.Dense(1, activation='sigmoid'))\n",
        "  \n",
        "  return modelo\n",
        "  \n",
        "def train_model(input_data, output_label, embedding_dimen, batch_size, epochs, validation_and_test_size):\n",
        "   \n",
        "    hp = keras_tuner.HyperParameters()\n",
        "\n",
        "    x_train, x_test, y_train, y_test = train_test_split(input_data, output_label, test_size=validation_and_test_size, random_state=42)\n",
        "\n",
        "    \n",
        "\n",
        "    optimizer = optimize(hp, LEARN_RATE, BETA_1, BETA_2, EPSILON)\n",
        "    \n",
        "    model = create_cnn(hp, VOCAB_SIZE, EMBEDDING_DIMENSION, MAX_TEXT_SIZE)\n",
        "    \n",
        "    model.summary()\n",
        "    model.compile(loss=tf.keras.losses.BinaryCrossentropy(), optimizer=optimizer, metrics=['accuracy'])        \n",
        "\n",
        "    ra_val = RocAucEvaluation(validation_data=(x_test, y_test), interval = 1)\n",
        "    csv_logger = CSVLogger('log.csv', append=False, separator=';')                                                                                       \n",
        "    \n",
        "    # print(\"Estou no Fit\")\n",
        "    # history = model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, validation_split = validation_and_test_size, verbose=2, use_multiprocessing=True,  callbacks = [ra_val, csv_logger])\n",
        "    print(\"Estou no Search\")\n",
        "    tuner_mlp = keras_tuner.tuners.BayesianOptimization(model, seed=42, objective='val_loss', max_trials=30, directory='.', project_name='tuning-cnn')\n",
        "    tuner_mlp.search(x_train, y_train, batch_size=batch_size, epochs=epochs, validation_split = validation_and_test_size, verbose=2, use_multiprocessing=True,  callbacks = [ra_val, csv_logger])\n",
        "    \n",
        "    \n",
        "    \n",
        "    # print(\"Estou no evaluate\")\n",
        "    # scores = model.evaluate(x_test, y_test, verbose=1)\n",
        "    \n",
        "    return history, model, x_test, y_test, ra_val, scores, csv_logger"
      ],
      "metadata": {
        "id": "32jDTCljHXqi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# plot dos gráficos\n",
        "history, model1, x_test, y_test, ra_val, scores, csv_logger = train_model(input_data, output_label, EMBEDDING_DIMENSION, BATCH_SIZE, EPOCHS, VAL_AND_TST_SIZE)"
      ],
      "metadata": {
        "id": "9YLL1kZTDzUG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "CsLnHIZw4JMH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_mlp_hyperparameters = tuner_mlp.get_best_hyperparameters(1)[0]\n",
        "print(\"Best Hyper-parameters\")\n",
        "best_mlp_hyperparameters.values"
      ],
      "metadata": {
        "id": "F_GyYU6iGl6H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_prob = model1.predict(x_test) \n",
        "\n",
        "y_labelpred = y_prob.round()\n",
        "\n",
        "y_labeltrue=y_test"
      ],
      "metadata": {
        "id": "FR-idj87D4-N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Parâmetros\n",
        "NOME_REDE = REDE_CNN\n",
        "NOME_BASE = BASE_2\n",
        "NOME_FUNCAO = FUNCAO_ATV_SIGMOID\n",
        "NOME_OTIMIZADOR = OTIMIZADOR_1\n",
        "\n",
        "train_resume = json.dumps(pd.read_csv('log.csv',sep=';').to_dict()) \n",
        "\n",
        "roc_curve =  json.dumps({\n",
        "    \"false_positive\": list(ra_val.false_positive_rate),\n",
        "    \"true_positive\": list(ra_val.true_positive_rate),\n",
        "    \"score\": ra_val.score\n",
        "})\n",
        "\n",
        "confusion = confusion_matrix(y_labeltrue,y_labelpred)\n",
        "confusion_dict = json.dumps({\n",
        "    \"00\": int(confusion[0][0]),\n",
        "    \"01\": int(confusion[0][1]),\n",
        "    \"10\": int(confusion[1][0]),\n",
        "    \"11\": int(confusion[1][1])\n",
        "})\n",
        "\n",
        "# Salvando resultado do modelo\n",
        "registro_resultado = {resultados.columns[0]: NOME_REDE, \n",
        "                      resultados.columns[1]: NOME_BASE, \n",
        "                      resultados.columns[2]: NOME_FUNCAO, \n",
        "                      resultados.columns[3]: NOME_OTIMIZADOR, \n",
        "                      resultados.columns[4]: scores[1],\n",
        "                      resultados.columns[5]: roc_curve,\n",
        "                      resultados.columns[6]: train_resume,\n",
        "                      resultados.columns[7]: confusion_dict}\n",
        "\n",
        "resultados = resultados.append(registro_resultado, ignore_index=True)\n",
        "resultados"
      ],
      "metadata": {
        "id": "wjgeZV9tsZVy",
        "outputId": "055afe50-3512-4067-97f4-360059ed05dc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 520
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   rede    base funcao_ativacao otimizador  acuracia  \\\n",
              "0   CNN  BASE 2         SIGMOID          1  0.919622   \n",
              "1   CNN  BASE 2         SIGMOID          1  0.925768   \n",
              "2   CNN  BASE 2         SIGMOID          1  0.928605   \n",
              "3   CNN  BASE 2         SIGMOID          1  0.921513   \n",
              "4   CNN  BASE 2         SIGMOID          1  0.927187   \n",
              "5   CNN  BASE 2         SIGMOID          1  0.908274   \n",
              "6   CNN  BASE 2         SIGMOID          1  0.930024   \n",
              "7   CNN  BASE 2         SIGMOID          1  0.930024   \n",
              "8   CNN  BASE 2         SIGMOID          1  0.922459   \n",
              "9   CNN  BASE 2         SIGMOID          1  0.911111   \n",
              "10  CNN  BASE 2         SIGMOID          1  0.930969   \n",
              "11  CNN  BASE 2         SIGMOID          1  0.920567   \n",
              "12  CNN  BASE 2         SIGMOID          1  0.936643   \n",
              "13  CNN  BASE 2         SIGMOID          1  0.927187   \n",
              "14  CNN  BASE 2         SIGMOID          1  0.927660   \n",
              "\n",
              "                                            roc_curve  \\\n",
              "0   {\"false_positive_rate\": [0.0, 0.0, 0.0, 0.0, 0...   \n",
              "1   {\"false_positive_rate\": [0.0, 0.0, 0.0, 0.0, 0...   \n",
              "2   {\"false_positive_rate\": [0.0, 0.0, 0.0, 0.0, 0...   \n",
              "3   {\"false_positive_rate\": [0.0, 0.0, 0.0, 0.0, 0...   \n",
              "4   {\"false_positive_rate\": [0.0, 0.0, 0.0, 0.0, 0...   \n",
              "5   {\"false_positive_rate\": [0.0, 0.0, 0.0, 0.0, 0...   \n",
              "6   {\"false_positive_rate\": [0.0, 0.0, 0.0, 0.0, 0...   \n",
              "7   {\"false_positive_rate\": [0.0, 0.0, 0.0, 0.0, 0...   \n",
              "8   {\"false_positive\": [0.0, 0.0, 0.0, 0.0, 0.0, 0...   \n",
              "9   {\"false_positive\": [0.0, 0.0, 0.0, 0.0, 0.0, 0...   \n",
              "10  {\"false_positive\": [0.0, 0.0, 0.0, 0.0, 0.0, 0...   \n",
              "11  {\"false_positive\": [0.0, 0.0, 0.0, 0.0, 0.0, 0...   \n",
              "12  {\"false_positive\": [0.0, 0.0, 0.0, 0.0, 0.0, 0...   \n",
              "13  {\"false_positive\": [0.0, 0.0, 0.0, 0.0, 0.0, 0...   \n",
              "14  {\"false_positive\": [0.0, 0.0, 0.0, 0.0, 0.0, 0...   \n",
              "\n",
              "                                         train_resume  \\\n",
              "0   {\"epoch\": {\"0\": 0, \"1\": 1, \"2\": 2, \"3\": 3, \"4\"...   \n",
              "1   {\"epoch\": {\"0\": 0, \"1\": 1, \"2\": 2, \"3\": 3, \"4\"...   \n",
              "2   {\"epoch\": {\"0\": 0, \"1\": 1, \"2\": 2, \"3\": 3, \"4\"...   \n",
              "3   {\"epoch\": {\"0\": 0, \"1\": 1, \"2\": 2, \"3\": 3, \"4\"...   \n",
              "4   {\"epoch\": {\"0\": 0, \"1\": 1, \"2\": 2, \"3\": 3, \"4\"...   \n",
              "5   {\"epoch\": {\"0\": 0, \"1\": 1, \"2\": 2, \"3\": 3, \"4\"...   \n",
              "6   {\"epoch\": {\"0\": 0, \"1\": 1, \"2\": 2, \"3\": 3, \"4\"...   \n",
              "7   {\"epoch\": {\"0\": 0, \"1\": 1, \"2\": 2, \"3\": 3, \"4\"...   \n",
              "8   {\"epoch\": {\"0\": 0, \"1\": 1, \"2\": 2, \"3\": 3, \"4\"...   \n",
              "9   {\"epoch\": {\"0\": 0, \"1\": 1, \"2\": 2, \"3\": 3, \"4\"...   \n",
              "10  {\"epoch\": {\"0\": 0, \"1\": 1, \"2\": 2, \"3\": 3, \"4\"...   \n",
              "11  {\"epoch\": {\"0\": 0, \"1\": 1, \"2\": 2, \"3\": 3, \"4\"...   \n",
              "12  {\"epoch\": {\"0\": 0, \"1\": 1, \"2\": 2, \"3\": 3, \"4\"...   \n",
              "13  {\"epoch\": {\"0\": 0, \"1\": 1, \"2\": 2, \"3\": 3, \"4\"...   \n",
              "14  {\"epoch\": {\"0\": 0, \"1\": 1, \"2\": 2, \"3\": 3, \"4\"...   \n",
              "\n",
              "                                confusion_matrix  \n",
              "0     {\"00\": 954, \"01\": 93, \"10\": 77, \"11\": 991}  \n",
              "1     {\"00\": 983, \"01\": 64, \"10\": 93, \"11\": 975}  \n",
              "2     {\"00\": 970, \"01\": 77, \"10\": 74, \"11\": 994}  \n",
              "3     {\"00\": 952, \"01\": 95, \"10\": 71, \"11\": 997}  \n",
              "4     {\"00\": 974, \"01\": 73, \"10\": 81, \"11\": 987}  \n",
              "5    {\"00\": 960, \"01\": 87, \"10\": 107, \"11\": 961}  \n",
              "6     {\"00\": 987, \"01\": 60, \"10\": 88, \"11\": 980}  \n",
              "7     {\"00\": 987, \"01\": 60, \"10\": 88, \"11\": 980}  \n",
              "8    {\"00\": 986, \"01\": 61, \"10\": 103, \"11\": 965}  \n",
              "9    {\"00\": 964, \"01\": 83, \"10\": 105, \"11\": 963}  \n",
              "10    {\"00\": 985, \"01\": 62, \"10\": 84, \"11\": 984}  \n",
              "11    {\"00\": 969, \"01\": 78, \"10\": 90, \"11\": 978}  \n",
              "12  {\"00\": 1014, \"01\": 33, \"10\": 101, \"11\": 967}  \n",
              "13   {\"00\": 952, \"01\": 95, \"10\": 59, \"11\": 1009}  \n",
              "14    {\"00\": 974, \"01\": 73, \"10\": 80, \"11\": 988}  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-82b50e2f-6f19-45a1-92f1-af8faa65e332\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>rede</th>\n",
              "      <th>base</th>\n",
              "      <th>funcao_ativacao</th>\n",
              "      <th>otimizador</th>\n",
              "      <th>acuracia</th>\n",
              "      <th>roc_curve</th>\n",
              "      <th>train_resume</th>\n",
              "      <th>confusion_matrix</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>CNN</td>\n",
              "      <td>BASE 2</td>\n",
              "      <td>SIGMOID</td>\n",
              "      <td>1</td>\n",
              "      <td>0.919622</td>\n",
              "      <td>{\"false_positive_rate\": [0.0, 0.0, 0.0, 0.0, 0...</td>\n",
              "      <td>{\"epoch\": {\"0\": 0, \"1\": 1, \"2\": 2, \"3\": 3, \"4\"...</td>\n",
              "      <td>{\"00\": 954, \"01\": 93, \"10\": 77, \"11\": 991}</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>CNN</td>\n",
              "      <td>BASE 2</td>\n",
              "      <td>SIGMOID</td>\n",
              "      <td>1</td>\n",
              "      <td>0.925768</td>\n",
              "      <td>{\"false_positive_rate\": [0.0, 0.0, 0.0, 0.0, 0...</td>\n",
              "      <td>{\"epoch\": {\"0\": 0, \"1\": 1, \"2\": 2, \"3\": 3, \"4\"...</td>\n",
              "      <td>{\"00\": 983, \"01\": 64, \"10\": 93, \"11\": 975}</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>CNN</td>\n",
              "      <td>BASE 2</td>\n",
              "      <td>SIGMOID</td>\n",
              "      <td>1</td>\n",
              "      <td>0.928605</td>\n",
              "      <td>{\"false_positive_rate\": [0.0, 0.0, 0.0, 0.0, 0...</td>\n",
              "      <td>{\"epoch\": {\"0\": 0, \"1\": 1, \"2\": 2, \"3\": 3, \"4\"...</td>\n",
              "      <td>{\"00\": 970, \"01\": 77, \"10\": 74, \"11\": 994}</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>CNN</td>\n",
              "      <td>BASE 2</td>\n",
              "      <td>SIGMOID</td>\n",
              "      <td>1</td>\n",
              "      <td>0.921513</td>\n",
              "      <td>{\"false_positive_rate\": [0.0, 0.0, 0.0, 0.0, 0...</td>\n",
              "      <td>{\"epoch\": {\"0\": 0, \"1\": 1, \"2\": 2, \"3\": 3, \"4\"...</td>\n",
              "      <td>{\"00\": 952, \"01\": 95, \"10\": 71, \"11\": 997}</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>CNN</td>\n",
              "      <td>BASE 2</td>\n",
              "      <td>SIGMOID</td>\n",
              "      <td>1</td>\n",
              "      <td>0.927187</td>\n",
              "      <td>{\"false_positive_rate\": [0.0, 0.0, 0.0, 0.0, 0...</td>\n",
              "      <td>{\"epoch\": {\"0\": 0, \"1\": 1, \"2\": 2, \"3\": 3, \"4\"...</td>\n",
              "      <td>{\"00\": 974, \"01\": 73, \"10\": 81, \"11\": 987}</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>CNN</td>\n",
              "      <td>BASE 2</td>\n",
              "      <td>SIGMOID</td>\n",
              "      <td>1</td>\n",
              "      <td>0.908274</td>\n",
              "      <td>{\"false_positive_rate\": [0.0, 0.0, 0.0, 0.0, 0...</td>\n",
              "      <td>{\"epoch\": {\"0\": 0, \"1\": 1, \"2\": 2, \"3\": 3, \"4\"...</td>\n",
              "      <td>{\"00\": 960, \"01\": 87, \"10\": 107, \"11\": 961}</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>CNN</td>\n",
              "      <td>BASE 2</td>\n",
              "      <td>SIGMOID</td>\n",
              "      <td>1</td>\n",
              "      <td>0.930024</td>\n",
              "      <td>{\"false_positive_rate\": [0.0, 0.0, 0.0, 0.0, 0...</td>\n",
              "      <td>{\"epoch\": {\"0\": 0, \"1\": 1, \"2\": 2, \"3\": 3, \"4\"...</td>\n",
              "      <td>{\"00\": 987, \"01\": 60, \"10\": 88, \"11\": 980}</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>CNN</td>\n",
              "      <td>BASE 2</td>\n",
              "      <td>SIGMOID</td>\n",
              "      <td>1</td>\n",
              "      <td>0.930024</td>\n",
              "      <td>{\"false_positive_rate\": [0.0, 0.0, 0.0, 0.0, 0...</td>\n",
              "      <td>{\"epoch\": {\"0\": 0, \"1\": 1, \"2\": 2, \"3\": 3, \"4\"...</td>\n",
              "      <td>{\"00\": 987, \"01\": 60, \"10\": 88, \"11\": 980}</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>CNN</td>\n",
              "      <td>BASE 2</td>\n",
              "      <td>SIGMOID</td>\n",
              "      <td>1</td>\n",
              "      <td>0.922459</td>\n",
              "      <td>{\"false_positive\": [0.0, 0.0, 0.0, 0.0, 0.0, 0...</td>\n",
              "      <td>{\"epoch\": {\"0\": 0, \"1\": 1, \"2\": 2, \"3\": 3, \"4\"...</td>\n",
              "      <td>{\"00\": 986, \"01\": 61, \"10\": 103, \"11\": 965}</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>CNN</td>\n",
              "      <td>BASE 2</td>\n",
              "      <td>SIGMOID</td>\n",
              "      <td>1</td>\n",
              "      <td>0.911111</td>\n",
              "      <td>{\"false_positive\": [0.0, 0.0, 0.0, 0.0, 0.0, 0...</td>\n",
              "      <td>{\"epoch\": {\"0\": 0, \"1\": 1, \"2\": 2, \"3\": 3, \"4\"...</td>\n",
              "      <td>{\"00\": 964, \"01\": 83, \"10\": 105, \"11\": 963}</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>CNN</td>\n",
              "      <td>BASE 2</td>\n",
              "      <td>SIGMOID</td>\n",
              "      <td>1</td>\n",
              "      <td>0.930969</td>\n",
              "      <td>{\"false_positive\": [0.0, 0.0, 0.0, 0.0, 0.0, 0...</td>\n",
              "      <td>{\"epoch\": {\"0\": 0, \"1\": 1, \"2\": 2, \"3\": 3, \"4\"...</td>\n",
              "      <td>{\"00\": 985, \"01\": 62, \"10\": 84, \"11\": 984}</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>CNN</td>\n",
              "      <td>BASE 2</td>\n",
              "      <td>SIGMOID</td>\n",
              "      <td>1</td>\n",
              "      <td>0.920567</td>\n",
              "      <td>{\"false_positive\": [0.0, 0.0, 0.0, 0.0, 0.0, 0...</td>\n",
              "      <td>{\"epoch\": {\"0\": 0, \"1\": 1, \"2\": 2, \"3\": 3, \"4\"...</td>\n",
              "      <td>{\"00\": 969, \"01\": 78, \"10\": 90, \"11\": 978}</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>CNN</td>\n",
              "      <td>BASE 2</td>\n",
              "      <td>SIGMOID</td>\n",
              "      <td>1</td>\n",
              "      <td>0.936643</td>\n",
              "      <td>{\"false_positive\": [0.0, 0.0, 0.0, 0.0, 0.0, 0...</td>\n",
              "      <td>{\"epoch\": {\"0\": 0, \"1\": 1, \"2\": 2, \"3\": 3, \"4\"...</td>\n",
              "      <td>{\"00\": 1014, \"01\": 33, \"10\": 101, \"11\": 967}</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>CNN</td>\n",
              "      <td>BASE 2</td>\n",
              "      <td>SIGMOID</td>\n",
              "      <td>1</td>\n",
              "      <td>0.927187</td>\n",
              "      <td>{\"false_positive\": [0.0, 0.0, 0.0, 0.0, 0.0, 0...</td>\n",
              "      <td>{\"epoch\": {\"0\": 0, \"1\": 1, \"2\": 2, \"3\": 3, \"4\"...</td>\n",
              "      <td>{\"00\": 952, \"01\": 95, \"10\": 59, \"11\": 1009}</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>CNN</td>\n",
              "      <td>BASE 2</td>\n",
              "      <td>SIGMOID</td>\n",
              "      <td>1</td>\n",
              "      <td>0.927660</td>\n",
              "      <td>{\"false_positive\": [0.0, 0.0, 0.0, 0.0, 0.0, 0...</td>\n",
              "      <td>{\"epoch\": {\"0\": 0, \"1\": 1, \"2\": 2, \"3\": 3, \"4\"...</td>\n",
              "      <td>{\"00\": 974, \"01\": 73, \"10\": 80, \"11\": 988}</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-82b50e2f-6f19-45a1-92f1-af8faa65e332')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-82b50e2f-6f19-45a1-92f1-af8faa65e332 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-82b50e2f-6f19-45a1-92f1-af8faa65e332');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 245
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Caso queira deletar uma linha use o código abaixo\n",
        "# Use a propriedade label para especificar o índice da linha\n",
        "#resultados = resultados.drop(labels=1, axis=0)\n",
        "#resultados = resultados.reset_index(drop=True)\n",
        "#resultados"
      ],
      "metadata": {
        "id": "nP3enYmss2v9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Salva arquivo de saída\n",
        "resultados.to_csv(PATH_ARQ_SAIDA)"
      ],
      "metadata": {
        "id": "y519ohA8u9jW"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}